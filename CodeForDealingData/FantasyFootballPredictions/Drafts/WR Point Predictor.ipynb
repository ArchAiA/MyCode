{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll try to build a WR stat predictor in this notebook. First lets load our full database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/richardknoche/anaconda/envs/py27/lib/python2.7/site-packages/matplotlib/__init__.py:1035: UserWarning: Duplicate key in file \"/Users/richardknoche/.matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from scipy.stats.stats import pearsonr \n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "samples=pd.read_csv('TrainingSamples.csv')\n",
    "samples.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "with open(\"stat_order.pickle\",'rb') as f:\n",
    "    stat_order=pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, lets remove the first year of football data (since the averages will be bad) and extract all of the WR players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WRsamples=samples[(samples['Position']==\"WR\") & (samples['Week']>100)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(WRsamples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of our lists got saved as strings in csv format, so lets convert them back to lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_lists = ['Opp Avg Stats','Opp Stat Std','Opp Avg Stats v Team','Opp Stat Std v Team',\\\n",
    "             'Opp Players','Player Avg Stats','Player Stat Std','Player Avg Stats v Opp',\\\n",
    "             'Player Stat Std v Opp','Team Avg Stats','Team Stat Std','Team Avg v Opp',\\\n",
    "             'Team Stat Std v Opp','Stat Outcome']\n",
    "\n",
    "for list in all_lists:\n",
    "    WRsamples[list] = WRsamples[list].apply(eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, lets remove any players that have \"nan\" stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WRsamples['No Player Stats'] = WRsamples.apply(lambda x: math.isnan(x['Player Avg Stats'][0]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WRsamples=WRsamples[WRsamples['No Player Stats']==False].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(WRsamples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now also remove players with very low average targets as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tarHist=np.hstack(WRsamples['Player Avg Stats'].apply(lambda x: x[stat_order.index('receiving_tar')]))\n",
    "plt.hist(tarHist, bins='auto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "WRsamples['High Receiving']=WRsamples['Player Avg Stats'].apply(lambda x: x[stat_order.index('receiving_tar')] > 4)\n",
    "WRsamples=WRsamples[WRsamples['High Receiving']==True].reset_index(drop=True)\n",
    "len(WRsamples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examining feature correlations for receiving yards\n",
    "\n",
    "We'll need to predict each WR stat separately.  The relevant scoring stats are:\n",
    "\n",
    "* Receiving Yards\n",
    "* Receptions\n",
    "* TD receptions\n",
    "* 2pt Receiving Conversion\n",
    "\n",
    "Technically, we should try to predict rushing yards, punt return td, etc as well.. but these are good for a start.\n",
    "\n",
    "Lets make some plots to see which features correlate with receving yards.  Here's a list of features that seem relevant:\n",
    "\n",
    "* player average: receiving_yds\n",
    "* player average: receiving_rec\n",
    "* player average: receiving_tds\n",
    "* player average: receiving_twoptm\n",
    "* player average: receiving_tar\n",
    "* player average: receiving_twopta\n",
    "* player average: receiving_yac_yds\n",
    "* team average: passing_yds\n",
    "* team average: passing_tds\n",
    "* team average: passing_twoptm\n",
    "* team average: passing_int\n",
    "* team average: passing_att\n",
    "* team average: passing_cmp\n",
    "* team average: passing_incmp\n",
    "* team average: passing_cmp_air_yds\n",
    "* team average: rushing_yds (maybe they pass less if they rush)\n",
    "* team average: rushing_att\n",
    "* opponent average: defense_sk\n",
    "* opponent average: defense_int\n",
    "* opponent average: defense_pass_def\n",
    "* opponent average: defense_rushing_yds_allowed\n",
    "* opponent average: defense_passing_yds_allowed\n",
    "* opponent average: defense_rushing_tds_allowed\n",
    "* opponent average: defense_passing_tds_allowed\n",
    "* opponent average: defense_points_allowed\n",
    "* Comparison: Team W/L to Opp W/L\n",
    "\n",
    "\n",
    "This is a long list.. but it's worth looking at all of the correlations here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def CalcCorr(x_stat_type,y_stat):\n",
    "    #x_stat is a stat in stat_order, such as \"receiving_yds\"\n",
    "    #x_stat_type is \"Player\" or \"Team\" or \"Opp\"\n",
    "    for x_stat in stat_order:\n",
    "        x_dfColumn = '%s Avg Stats' % x_stat_type\n",
    "\n",
    "        all_x_stats =  WRsamples[x_dfColumn] \n",
    "        all_y_stats =  WRsamples['Stat Outcome'] \n",
    "\n",
    "        x_stats = all_x_stats.apply(lambda x: x[stat_order.index(x_stat)])\n",
    "        y_stats = all_y_stats.apply(lambda x: x[stat_order.index(y_stat)])\n",
    "\n",
    "        if abs(pearsonr(x_stats, y_stats)[0]) > 0.1:\n",
    "            print x_stat_type, x_stat, \"Correlation:\", pearsonr(x_stats, y_stats)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CalcCorr('Player','receiving_yds')\n",
    "CalcCorr('Team','receiving_yds')    \n",
    "CalcCorr('Opp','receiving_yds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's pretty surprising that's there is no correlation between the opponent's passing yards allowed and the outcome of the player's receiving yards... Let's plot that to look into it a little further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "def PlotCorr(x_stat,x_stat_type,y_stat):\n",
    "    #x_stat is a stat in stat_order, such as \"receiving_yds\"\n",
    "    #x_stat_type is \"Player\" or \"Team\" or \"Opp\"\n",
    "    x_dfColumn = '%s Avg Stats' % x_stat_type\n",
    "    \n",
    "    all_x_stats =  WRsamples[x_dfColumn] \n",
    "    all_y_stats =  WRsamples['Stat Outcome'] \n",
    "\n",
    "    x_stats = all_x_stats.apply(lambda x: x[stat_order.index(x_stat)])\n",
    "    y_stats = all_y_stats.apply(lambda x: x[stat_order.index(y_stat)])\n",
    "\n",
    "    xy = np.vstack([x_stats,y_stats])\n",
    "    z = gaussian_kde(xy)(xy)\n",
    "    idx = z.argsort()\n",
    "    x, y, z = x_stats[idx], y_stats[idx], z[idx]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(x, y, c=z, s=50, edgecolor='')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PlotCorr('defense_passing_yds_allowed','Opp','receiving_yds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting... there isn't a huge spread in the allowed passing yards of teams, and there really doesn't look like there's any correlation here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PlotCorr('passing_yds','Team','receiving_yds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For team's passing yards, there are clearly two types of team... a high passing yards group and a low passing yards group.  Surprisingly, the high passing yards group doesn't seem to have higher yards for each player.  Instead, they must be passing to a wider range of players."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a predictor\n",
    "\n",
    "Okay, for now lets use the seven features that have abs(correlation) > 0.1 to training our predictor.  We might add more features based on our CV results later.\n",
    "\n",
    "First, we need to split our sample into training, CV, and testing sets.  Let's randomly order our dataframe, using the same seed so that we get the same order every time we run this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "WRsamples=WRsamples.reindex(np.random.permutation(WRsamples.index))\n",
    "WRsamples.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets put half of the samples in training, a quarter in CV, and a quarter in test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WR_training = WRsamples.ix[:round(len(WRsamples)/2)]\n",
    "WR_cv = WRsamples.ix[round(len(WRsamples)/2): round(len(WRsamples)/2) + round(len(WRsamples)/4)]\n",
    "WR_test = WRsamples.ix[round(len(WRsamples)/2) + round(len(WRsamples)/4):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WR_training['Discard']=WR_training['Stat Outcome'].apply(lambda x: x[stat_order.index('receiving_yds')]==0)\n",
    "WR_cv['Discard']=WR_cv['Stat Outcome'].apply(lambda x: x[stat_order.index('receiving_yds')]==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WR_training=WR_training[WR_training['Discard']==False]\n",
    "WR_cv=WR_cv[WR_cv['Discard']==False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets train a simple prediction model before trying anything fancy. First we'll try a linear regression model, then we'll try a nonlinear regression model, then we'll try a neural network.  As a reminder, here's the features that have a correlation with a player's receiving yard outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "player_feats=['receiving_yds','receiving_rec','receiving_tar','receiving_yac_yds']\n",
    "team_feats=[]\n",
    "opp_feats=[]\n",
    "\n",
    "all_feats=[player_feats,team_feats,opp_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Extract the features we want\n",
    "def getFeats(row,feats):\n",
    "    feat_df=pd.DataFrame()\n",
    "    feat_list=[]\n",
    "    \n",
    "    #Player feats\n",
    "    feat_list= [row['Player Avg Stats'][stat_order.index(feat)] for feat in feats[0]]\n",
    "\n",
    "    #Team feats\n",
    "    feat_list = feat_list + [row['Team Avg Stats'][stat_order.index(feat)] for feat in feats[1]]\n",
    "\n",
    "    #Opponent feats\n",
    "    feat_list = feat_list + [row['Opp Avg Stats'][stat_order.index(feat)] for feat in feats[2]]\n",
    "\n",
    "    return feat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=pd.DataFrame(WR_training.apply(getFeats,args=[all_feats],axis=1).tolist())\n",
    "X_cv=pd.DataFrame(WR_cv.apply(getFeats,args=[all_feats],axis=1).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Extract feature names for column names\n",
    "def getFeatNames(feats):\n",
    "    feat_names=[]\n",
    "    \n",
    "    for feat in feats[0]:\n",
    "        feat_names = feat_names + ['player_%s' % feat]\n",
    "    for feat in feats[1]:\n",
    "        feat_names = feat_names + ['team_%s' % feat]\n",
    "    for feat in feats[2]:\n",
    "        feat_names = feat_names + ['opp_%s' % feat]\n",
    "    \n",
    "    return feat_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train.columns=getFeatNames(all_feats)\n",
    "X_cv.columns=getFeatNames(all_feats)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Scale the features to help with fitting\n",
    "\n",
    "#Get min and max of each feature in from the data set\n",
    "def getExtremeOfFeat(feat,feat_type):\n",
    "    #Player feats\n",
    "    feat_list = WRsamples.apply(lambda x: x['%s Avg Stats' % feat_type][stat_order.index(feat)],axis=1).tolist()\n",
    "\n",
    "    return (max(feat_list),min(feat_list))\n",
    "\n",
    "def scaleFeat(featFrame,feats):\n",
    "    \n",
    "    #player feats\n",
    "    for feat in feats[0]:\n",
    "        (max_feat,min_feat)=getExtremeOfFeat(feat,'Player')\n",
    "        featFrame['player_%s' % feat]= (featFrame['player_%s' % feat] - min_feat)/(max_feat-min_feat)\n",
    "    \n",
    "    #team feats\n",
    "    for feat in feats[1]:\n",
    "        (max_feat,min_feat)=getExtremeOfFeat(feat,'Team')\n",
    "        featFrame['team_%s' % feat]= (featFrame['team_%s' % feat] - min_feat)/(max_feat-min_feat)\n",
    "    \n",
    "    #opp feats\n",
    "    for feat in feats[2]:\n",
    "        (max_feat,min_feat)=getExtremeOfFeat(feat,'Opp')\n",
    "        featFrame['opp_%s' % feat]= (featFrame['opp_%s' % feat] - min_feat)/(max_feat-min_feat)\n",
    "        \n",
    "    return featFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaleFeat(X_train,all_feats)\n",
    "scaleFeat(X_cv,all_feats)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get outcome for the stat we are predicting\n",
    "def getStatRes(row,stat):\n",
    "    return row['Stat Outcome'][stat_order.index(stat)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_train=WR_training.apply(getStatRes,args=['receiving_yds'],axis=1)\n",
    "Y_cv=WR_cv.apply(getStatRes,args=['receiving_yds'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Train a Linear regression model\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train,Y_train)\n",
    "\n",
    "#Check performance on CV data\n",
    "plt.scatter(Y_cv, lm.predict(X_cv))\n",
    "plt.xlabel(\"True Receiving Yards\")\n",
    "plt.ylabel(\"Predicted Reveiving Yards\")\n",
    "\n",
    "\n",
    "#Calculate mean squared error\n",
    "mse = np.mean((Y_cv - lm.predict(X_cv)) **2)\n",
    "print 'MSE:', np.sqrt(mse)\n",
    "print 'Average Yardage:', np.mean(Y_cv)\n",
    "print 'Correlation: ', pearsonr(Y_cv,lm.predict(X_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "svr_rbf = SVR(kernel='rbf', C=1e3, gamma=0.1)\n",
    "svr_lin = SVR(kernel='linear', C=1e3)\n",
    "svr_poly = SVR(kernel='poly', C=1e3, degree=2)\n",
    "from sklearn import svm\n",
    "\n",
    "lm=svr_rbf\n",
    "#lm=svr_lin\n",
    "lm.fit(X_train,Y_train)\n",
    "\n",
    "\n",
    "#Check performance on CV data\n",
    "plt.scatter(Y_cv, lm.predict(X_cv))\n",
    "plt.xlabel(\"True Receiving Yards\")\n",
    "plt.ylabel(\"Predicted Reveiving Yards\")\n",
    "\n",
    "\n",
    "#Calculate mean squared error\n",
    "mse = np.mean((Y_cv - lm.predict(X_cv)) **2)\n",
    "print 'MSE:', np.sqrt(mse)\n",
    "print 'Average Yardage:', np.mean(Y_cv)\n",
    "print 'Correlation: ', pearsonr(Y_cv,lm.predict(X_cv))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Bayesian Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "lm = BayesianRidge(compute_score=True)\n",
    "lm.fit(X_train,Y_train)\n",
    "\n",
    "#Check performance on CV data\n",
    "plt.scatter(Y_cv, lm.predict(X_cv))\n",
    "plt.xlabel(\"True Receiving Yards\")\n",
    "plt.ylabel(\"Predicted Reveiving Yards\")\n",
    "\n",
    "\n",
    "#Calculate mean squared error\n",
    "mse = np.mean((Y_cv - lm.predict(X_cv)) **2)\n",
    "print 'MSE:', np.sqrt(mse)\n",
    "print 'Average Yardage:', np.mean(Y_cv)\n",
    "print 'Correlation: ', pearsonr(Y_cv,lm.predict(X_cv))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "lm = ElasticNet(alpha=0.05,random_state=1)\n",
    "lm.fit(X_train,Y_train)\n",
    "\n",
    "#Check performance on CV data\n",
    "plt.scatter(Y_cv, lm.predict(X_cv))\n",
    "plt.xlabel(\"True Receiving Yards\")\n",
    "plt.ylabel(\"Predicted Reveiving Yards\")\n",
    "\n",
    "\n",
    "#Calculate mean squared error\n",
    "mse = np.mean((Y_cv - lm.predict(X_cv)) **2)\n",
    "print 'MSE:', np.sqrt(mse)\n",
    "print 'Average Yardage:', np.mean(Y_cv)\n",
    "print 'Correlation: ', pearsonr(Y_cv,lm.predict(X_cv))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "lm = MLPClassifier()\n",
    "\n",
    "lm.fit(X_train,Y_train)\n",
    "\n",
    "\n",
    "#Check performance on CV data\n",
    "plt.scatter(Y_cv, lm.predict(X_cv))\n",
    "plt.xlabel(\"True Receiving Yards\")\n",
    "plt.ylabel(\"Predicted Reveiving Yards\")\n",
    "\n",
    "\n",
    "#Calculate mean squared error\n",
    "mse = np.mean((Y_cv - lm.predict(X_cv)) **2)\n",
    "print 'MSE:', np.sqrt(mse)\n",
    "print 'Average Yardage:', np.mean(Y_cv)\n",
    "print 'Correlation: ', pearsonr(Y_cv,lm.predict(X_cv))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py27]",
   "language": "python",
   "name": "Python [py27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
