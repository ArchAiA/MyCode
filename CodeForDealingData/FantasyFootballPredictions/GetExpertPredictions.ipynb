{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/richardknoche/anaconda/envs/py27/lib/python2.7/site-packages/matplotlib/__init__.py:1035: UserWarning: Duplicate key in file \"/Users/richardknoche/.matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "#connect to nfldb and load gameStats dataframe\n",
    "import nfldb\n",
    "import pandas as pd\n",
    "import urllib2\n",
    "from lxml import etree\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4 import Comment\n",
    "from urllib import urlopen\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "db = nfldb.connect()\n",
    "gameStats = pd.read_csv('gameStats_withFeats_v2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a \"season week\" and \"year\" column to the data frame, for easy cross checking with the web crawling results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gameStats['Year']=gameStats['Season']+2008\n",
    "gameStats['SeasonWeek']=gameStats['Week']-17*(gameStats['Season']-1)\n",
    "\n",
    "gameStats['Expert Rank']=None\n",
    "gameStats['Average Expert Rank']=None\n",
    "gameStats['Best Expert Rank']=None\n",
    "gameStats['Worst Expert Rank']=None\n",
    "gameStats['Injury Status']=None\n",
    "\n",
    "gameStats['PPR Expert Rank']=None\n",
    "gameStats['PPR Average Expert Rank']=None\n",
    "gameStats['PPR Best Expert Rank']=None\n",
    "gameStats['PPR Worst Expert Rank']=None\n",
    "gameStats['PPR Injury Status']=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the chached fantasy pros web page with beautiful soup. Trying 2011 format first.  Note- there is no 2013 archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/richardknoche/anaconda/envs/py27/lib/python2.7/site-packages/bs4/__init__.py:166: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "To get rid of this warning, change this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with 09/3\n",
      "Done with 09/6\n",
      "Done with 09/9\n",
      "Done with 09/12\n",
      "Done with 09/15\n",
      "Done with 09/18\n",
      "Done with 09/21\n",
      "Done with 09/24\n",
      "Done with 09/27\n",
      "Done with 09/30\n",
      "Done with 10/3\n",
      "Done with 10/6\n",
      "Done with 10/9\n",
      "Done with 10/12\n",
      "Done with 10/15\n",
      "Done with 10/18\n",
      "Done with 10/21\n",
      "Done with 10/24\n",
      "Done with 10/27\n",
      "Done with 10/30\n",
      "Done with 11/3\n",
      "Done with 11/6\n",
      "Done with 11/9\n",
      "Done with 11/12\n",
      "Done with 11/15\n",
      "Done with 11/18\n",
      "Done with 11/21\n",
      "Done with 11/24\n",
      "Done with 11/27\n",
      "Done with 11/30\n",
      "Done with 12/3\n",
      "Done with 12/6\n",
      "Done with 12/9\n",
      "Done with 12/12\n",
      "Done with 12/15\n",
      "Done with 12/18\n",
      "Done with 12/21\n",
      "Done with 12/24\n",
      "Done with 12/27\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 12/30\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 01/3\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 01/6\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 01/9\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 01/12\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 01/15\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 01/18\n",
      "Warning: Web year and Season Year mismatch.  Web month is Feb\n",
      "Warning: Web year and Season Year mismatch.  Web month is Feb\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 01/21\n",
      "Warning: Web year and Season Year mismatch.  Web month is Feb\n",
      "Warning: Web year and Season Year mismatch.  Web month is Feb\n",
      "Warning: Web year and Season Year mismatch.  Web month is Feb\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 01/24\n",
      "Warning: Web year and Season Year mismatch.  Web month is Feb\n",
      "Warning: Web year and Season Year mismatch.  Web month is Feb\n",
      "Warning: Web year and Season Year mismatch.  Web month is Feb\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 01/27\n",
      "Warning: Web year and Season Year mismatch.  Web month is Feb\n",
      "Warning: Web year and Season Year mismatch.  Web month is Feb\n",
      "Warning: Web year and Season Year mismatch.  Web month is Feb\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 01/30\n"
     ]
    }
   ],
   "source": [
    "year='2011'\n",
    "\n",
    "#Season starts first week in September, ends at end of December\n",
    "for month in ['09','10','11','12','01']:\n",
    "    for day in range(3,31,3):\n",
    "        for pos in ['wr','rb','te','qb']:\n",
    "            web_add = 'https://web.archive.org/web/%s%s%s/http://www.fantasypros.com/nfl/rankings/%s.php' % (year,str(month).zfill(2),str(day).zfill(2),pos)\n",
    "\n",
    "            #Check Jan of the next year too\n",
    "            if month=='01':   \n",
    "                web_add = 'https://web.archive.org/web/%s%s%s/http://www.fantasypros.com/nfl/rankings/%s.php' % (str(int(year)+1),str(month).zfill(2),str(day).zfill(2),pos)\n",
    "            \n",
    "            web_html = urlopen(web_add).read()\n",
    "            soup = BeautifulSoup(web_html)\n",
    "\n",
    "            #Check if unavailable issue\n",
    "            #If it's there, retry in 10 seconds\n",
    "            while 'Service Unavailable' in soup.text:\n",
    "                print 'No Server Avaialble.  Trying Again in 10 seconds...'\n",
    "                time.sleep(10)\n",
    "                web_html = urlopen(web_add).read()\n",
    "                soup = BeautifulSoup(web_html)\n",
    "\n",
    "            #Get the week and year of the predictions\n",
    "            title= soup.find(\"title\")\n",
    "            web_week=int(title.text.split(' ')[1])\n",
    "            \n",
    "            #catch week 17 leaking into the start of the year\n",
    "            if (month=='09') and (int(web_week)>10):\n",
    "                print \"Warning: Web week %s found in month 09\" % web_week\n",
    "\n",
    "            comments=soup.find_all(string=lambda text:isinstance(text,Comment))\n",
    "            web_year = comments[-1].split(' ')[11]\n",
    "            web_month = comments[-1].split(' ')[9]\n",
    "            if web_year != year:\n",
    "                print \"Warning: Web year and Season Year mismatch.  Web month is %s\" % web_month\n",
    "            \n",
    "            #Get the player rankings and injury status\n",
    "            table= soup.find(\"table\", { \"id\" : \"data\"} )\n",
    "\n",
    "            #Skip the first row of the table, since it is header info\n",
    "            rows=table.findAll('tr')\n",
    "            iterrows = iter(rows)\n",
    "            next(iterrows)\n",
    "\n",
    "            #Iterate over reaming rows\n",
    "            for tr in iterrows:\n",
    "\n",
    "                #Find all columns and exctract info\n",
    "                cols = tr.findAll('td')  \n",
    "                \n",
    "                #Skip empty rows and free agents (cols[4].find('a') empty means free agent)\n",
    "                if cols[3].find('a').contents and cols[4].find('a'):\n",
    "                    team = cols[4].find('a').contents[0] #Uses JAC already        \n",
    "                    player = cols[3].find('a').contents[0]   \n",
    "\n",
    "                    #If the player isn't in our database, find the closest matching name\n",
    "                    #It's okay if it comes back with bull, since the player + team + season + week\n",
    "                    #combo will prevent it from being entered\n",
    "                    if player not in gameStats['Player'].tolist():\n",
    "                        player = str(nfldb.player_search(db,player)[0])\n",
    "\n",
    "                    rank=cols[0].text\n",
    "                    best_rank=cols[1].text\n",
    "                    worst_rank=cols[2].text\n",
    "                    if len(cols[6].contents)>1:\n",
    "                        injury_status=cols[6].contents[1][0]\n",
    "                    else:\n",
    "                        injury_status='H' #H for healthy\n",
    "\n",
    "                    #Use player,team,week,and year to fill in the information in our dataframe        \n",
    "                    selector=( (gameStats.Player==player) & (gameStats.Team ==team) &\\\n",
    "                               (gameStats.SeasonWeek==int(web_week)) & (gameStats.Year==float(year)) )\n",
    "\n",
    "\n",
    "                    #If there is a player,team,season,and week match.. fill in the data\n",
    "                    if len(gameStats[selector])>0: \n",
    "                        gameStats.ix[selector, 'Expert Rank'] = rank\n",
    "                        #No average rank available\n",
    "                        gameStats.ix[selector, 'Best Expert Rank']=best_rank\n",
    "                        gameStats.ix[selector, 'Worst Expert Rank']=worst_rank\n",
    "                        gameStats.ix[selector, 'Injury Status']=injury_status\n",
    "                        \n",
    "        print 'Done with %s/%s' % (month,day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gameStats.to_csv('gameStats_withExperts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with 09/3\n",
      "Done with 09/6\n",
      "Done with 09/9\n",
      "Done with 09/12\n",
      "Done with 09/15\n",
      "Done with 09/18\n",
      "Done with 09/21\n",
      "Done with 09/24\n",
      "Done with 09/27\n",
      "Done with 09/30\n",
      "Done with 10/3\n",
      "Done with 10/6\n",
      "Done with 10/9\n",
      "Done with 10/12\n",
      "Done with 10/15\n",
      "Done with 10/18\n",
      "Done with 10/21\n",
      "Done with 10/24\n",
      "Done with 10/27\n",
      "Done with 10/30\n",
      "Done with 11/3\n",
      "Done with 11/6\n",
      "Done with 11/9\n",
      "Done with 11/12\n",
      "Done with 11/15\n",
      "Done with 11/18\n",
      "Done with 11/21\n",
      "Done with 11/24\n",
      "Done with 11/27\n",
      "Done with 11/30\n",
      "Done with 12/3\n",
      "Done with 12/6\n",
      "Done with 12/9\n",
      "Done with 12/12\n",
      "Done with 12/15\n",
      "Done with 12/18\n",
      "Done with 12/21\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 12/24\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 12/27\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 12/30\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 01/3\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 01/6\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 01/9\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 01/12\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 01/15\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 01/18\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 01/21\n",
      "Warning: Web year and Season Year mismatch.  Web month is Feb\n",
      "Warning: Web year and Season Year mismatch.  Web month is Feb\n",
      "Warning: Web year and Season Year mismatch.  Web month is Feb\n",
      "Done with 01/24\n",
      "Warning: Web year and Season Year mismatch.  Web month is Feb\n",
      "Warning: Web year and Season Year mismatch.  Web month is Feb\n",
      "Warning: Web year and Season Year mismatch.  Web month is Feb\n",
      "Done with 01/27\n",
      "Warning: Web year and Season Year mismatch.  Web month is Feb\n",
      "Warning: Web year and Season Year mismatch.  Web month is Feb\n",
      "Warning: Web year and Season Year mismatch.  Web month is Feb\n",
      "Done with 01/30\n"
     ]
    }
   ],
   "source": [
    "#PPR version\n",
    "year='2011'\n",
    "\n",
    "#Season starts first week in September, ends at end of December\n",
    "for month in ['09','10','11','12','01']:\n",
    "    for day in range(3,31,3):\n",
    "        for pos in ['wr','rb','te']:\n",
    "            web_add = 'https://web.archive.org/web/%s%s%s/http://www.fantasypros.com/nfl/rankings/ppr-%s.php' % (year,str(month).zfill(2),str(day).zfill(2),pos)\n",
    "\n",
    "            #Check Jan of the next year too\n",
    "            if month=='01':   \n",
    "                web_add = 'https://web.archive.org/web/%s%s%s/http://www.fantasypros.com/nfl/rankings/ppr-%s.php' % (str(int(year)+1),str(month).zfill(2),str(day).zfill(2),pos)\n",
    "             \n",
    "            web_html = urlopen(web_add).read()\n",
    "            soup = BeautifulSoup(web_html)\n",
    "\n",
    "            #Check if unavailable issue\n",
    "            #If it's there, retry in 10 seconds\n",
    "            while 'Service Unavailable' in soup.text:\n",
    "                print 'No Server Avaialble.  Trying Again in 10 seconds...'\n",
    "                time.sleep(10)\n",
    "                web_html = urlopen(web_add).read()\n",
    "                soup = BeautifulSoup(web_html)\n",
    "\n",
    "            #Get the week and year of the predictions\n",
    "            title= soup.find(\"title\")\n",
    "            web_week=int(title.text.split(' ')[1])\n",
    "\n",
    "            #catch week 17 leaking into the start of the year\n",
    "            if (month=='09') and (int(web_week)>10):\n",
    "                print \"Warning: Web week %s found in month 09\" % web_week\n",
    "            \n",
    "            \n",
    "            comments=soup.find_all(string=lambda text:isinstance(text,Comment))\n",
    "            web_year = comments[-1].split(' ')[11]\n",
    "            web_month = comments[-1].split(' ')[9]\n",
    "            if web_year != year:\n",
    "                print \"Warning: Web year and Season Year mismatch.  Web month is %s\" % web_month\n",
    "\n",
    "\n",
    "            #Get the player rankings and injury status\n",
    "            table= soup.find(\"table\", { \"id\" : \"data\"} )\n",
    "\n",
    "            #Skip the first row of the table, since it is header info\n",
    "            rows=table.findAll('tr')\n",
    "            iterrows = iter(rows)\n",
    "            next(iterrows)\n",
    "\n",
    "            #Iterate over reaming rows\n",
    "            for tr in iterrows:\n",
    "\n",
    "                #Find all columns and exctract info\n",
    "                cols = tr.findAll('td')  \n",
    "                \n",
    "                #Skip empty rows and free agents (cols[4].find('a') empty means free agent)\n",
    "                if cols[3].find('a').contents and cols[4].find('a'):\n",
    "                    team = cols[4].find('a').contents[0] #Uses JAC already        \n",
    "                    player = cols[3].find('a').contents[0]   \n",
    "\n",
    "                    #If the player isn't in our database, find the closest matching name\n",
    "                    #It's okay if it comes back with bull, since the player + team + season + week\n",
    "                    #combo will prevent it from being entered\n",
    "                    if player not in gameStats['Player'].tolist():\n",
    "                        player = str(nfldb.player_search(db,player)[0])\n",
    "\n",
    "                    rank=cols[0].text\n",
    "                    best_rank=cols[1].text\n",
    "                    worst_rank=cols[2].text\n",
    "                    if len(cols[6].contents)>1:\n",
    "                        injury_status=cols[6].contents[1][0]\n",
    "                    else:\n",
    "                        injury_status='H' #H for healthy\n",
    "\n",
    "                    #Use player,team,week,and year to fill in the information in our dataframe        \n",
    "                    selector=( (gameStats.Player==player) & (gameStats.Team ==team) &\\\n",
    "                               (gameStats.SeasonWeek==int(web_week)) & (gameStats.Year==float(year)) )\n",
    "\n",
    "\n",
    "                    #If there is a player,team,season,and week match.. fill in the data\n",
    "                    if len(gameStats[selector])>0: \n",
    "                        gameStats.ix[selector, 'PPR Expert Rank'] = rank\n",
    "                        #No average rank available\n",
    "                        gameStats.ix[selector, 'PPR Best Expert Rank']=best_rank\n",
    "                        gameStats.ix[selector, 'PPR Worst Expert Rank']=worst_rank\n",
    "                        gameStats.ix[selector, 'PPR Injury Status']=injury_status\n",
    "                        \n",
    "        print 'Done with %s/%s' % (month,day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gameStats.to_csv('gameStats_withExperts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with 09/3\n",
      "Done with 09/6\n",
      "Done with 09/9\n",
      "Done with 09/12\n",
      "Done with 09/15\n",
      "Done with 09/18\n",
      "Done with 09/21\n",
      "Done with 09/24\n",
      "Done with 09/27\n",
      "Done with 09/30\n",
      "Done with 10/3\n",
      "Done with 10/6\n",
      "Done with 10/9\n",
      "Error parsing year info - using previous query info\n",
      "Error parsing year info - using previous query info\n",
      "Error parsing year info - using previous query info\n",
      "Error parsing year info - using previous query info\n",
      "Done with 10/12\n",
      "Error parsing year info - using previous query info\n",
      "Error parsing year info - using previous query info\n",
      "Error parsing year info - using previous query info\n",
      "Done with 10/15\n",
      "Done with 10/18\n",
      "Done with 10/21\n",
      "Done with 10/24\n",
      "Done with 10/27\n",
      "Done with 10/30\n",
      "Done with 11/3\n",
      "Done with 11/6\n",
      "Done with 11/9\n",
      "Done with 11/12\n",
      "Done with 11/15\n",
      "Done with 11/18\n",
      "Done with 11/21\n",
      "Done with 11/24\n",
      "Done with 11/27\n",
      "Done with 11/30\n",
      "Done with 12/3\n",
      "Done with 12/6\n",
      "Done with 12/9\n",
      "Done with 12/12\n",
      "Done with 12/15\n",
      "Done with 12/18\n",
      "Done with 12/21\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 12/24\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 12/27\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 12/30\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 01/3\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 01/6\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 01/9\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 01/12\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 01/15\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 01/18\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 01/21\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 01/24\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 01/27\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 01/30\n"
     ]
    }
   ],
   "source": [
    "year='2012'\n",
    "\n",
    "#Season starts first week in September, ends at end of December\n",
    "for month in ['09','10','11','12','01']:\n",
    "    for day in range(3,31,3):\n",
    "        for pos in ['wr','rb','te','qb']:\n",
    "            web_add = 'https://web.archive.org/web/%s%s%s/http://www.fantasypros.com/nfl/rankings/%s.php' % (year,str(month).zfill(2),str(day).zfill(2),pos)\n",
    "\n",
    "            #Check Jan of the next year too\n",
    "            if month=='01':   \n",
    "                web_add = 'https://web.archive.org/web/%s%s%s/http://www.fantasypros.com/nfl/rankings/%s.php' % (str(int(year)+1),str(month).zfill(2),str(day).zfill(2),pos)\n",
    "  \n",
    "            web_html = urlopen(web_add).read()\n",
    "            soup = BeautifulSoup(web_html)\n",
    "\n",
    "            #Check if unavailable issue\n",
    "            #If it's there, retry in 10 seconds\n",
    "            while 'Service Unavailable' in soup.text:\n",
    "                print 'No Server Avaialble.  Trying Again in 10 seconds...'\n",
    "                time.sleep(10)\n",
    "                web_html = urlopen(web_add).read()\n",
    "                soup = BeautifulSoup(web_html)\n",
    "\n",
    "            #Get the week and year of the predictions\n",
    "            title= soup.find(\"title\")\n",
    "            web_week=int(title.text.split(' ')[1])\n",
    "\n",
    "            #catch week 17 leaking into the start of the year\n",
    "            if (month=='09') and (int(web_week)>10):\n",
    "                print \"Warning: Web week %s found in month 09\" % web_week\n",
    "            \n",
    "            \n",
    "            comments=soup.find_all(string=lambda text:isinstance(text,Comment))\n",
    "            if 'FILE ARCHIVED' in soup.find_all(string=lambda text:isinstance(text,Comment))[-1]:            \n",
    "                web_year = comments[-1].split(' ')[11]\n",
    "                web_month = comments[-1].split(' ')[9]\n",
    "                if web_year != year:\n",
    "                    print \"Warning: Web year and Season Year mismatch.  Web month is %s\" % web_month\n",
    "\n",
    "            else:\n",
    "                print 'Error parsing year info - using previous query info' \n",
    "                #this is fine as long as it doesn't happen on the first query\n",
    "\n",
    "            #Get the player rankings and injury status\n",
    "            table= soup.find(\"table\", { \"id\" : \"data\"} )\n",
    "\n",
    "            #Skip the first row of the table, since it is header info\n",
    "            rows=table.findAll('tr')\n",
    "            iterrows = iter(rows)\n",
    "            next(iterrows)\n",
    "\n",
    "            #Iterate over reaming rows\n",
    "            for tr in iterrows:\n",
    "\n",
    "                #Find all columns and exctract info\n",
    "                cols = tr.findAll('td')  \n",
    "\n",
    "                #Skip empty rows and free agents (cols[4].find('a') empty means free agent)\n",
    "                if cols[1].find('a').contents:\n",
    "                    team = cols[1].find('span',{'class':'tiny'}).text.split(' ')[0][1:]   \n",
    "                    player = cols[1].find('a').contents[0]\n",
    "\n",
    "                    #If the player isn't in our database, find the closest matching name\n",
    "                    #It's okay if it comes back with bull, since the player + team + season + week\n",
    "                    #combo will prevent it from being entered\n",
    "                    if player not in gameStats['Player'].tolist():\n",
    "                        player = str(nfldb.player_search(db,player)[0])\n",
    "\n",
    "                    rank=cols[0].text\n",
    "                    best_rank=cols[2].text\n",
    "                    worst_rank=cols[3].text\n",
    "                    average_rank=cols[4].text\n",
    "\n",
    "                    #Check for old format where they use an image\n",
    "                    if cols[1].find('img'):\n",
    "                        injury_status=cols[1].find('img').get('title')[0]         \n",
    "                    #Check for the end of year format where they use a red letter instead of img\n",
    "                    elif len(cols[1].findAll('span',{'class':'tiny'}))>1:\n",
    "                        injury_status=cols[1].findAll('span',{'class':'tiny'})[1].text\n",
    "                    else:\n",
    "                        injury_status='H' #H for healthy\n",
    "\n",
    "                    #Use player,team,week,and year to fill in the information in our dataframe        \n",
    "                    selector=( (gameStats.Player==player) & (gameStats.Team ==team) &\\\n",
    "                               (gameStats.SeasonWeek==int(web_week)) & (gameStats.Year==float(year)) )\n",
    "\n",
    "\n",
    "                    #If there is a player,team,season,and week match.. fill in the data\n",
    "                    if len(gameStats[selector])>0: \n",
    "                        gameStats.ix[selector, 'Expert Rank'] = rank         \n",
    "                        gameStats.ix[selector, 'Average Expert Rank'] = average_rank\n",
    "                        gameStats.ix[selector, 'Best Expert Rank']=best_rank\n",
    "                        gameStats.ix[selector, 'Worst Expert Rank']=worst_rank\n",
    "                        gameStats.ix[selector, 'Injury Status']=injury_status\n",
    "                        \n",
    "        print 'Done with %s/%s' % (month,day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gameStats.to_csv('gameStats_withExperts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with 09/3\n",
      "Done with 09/6\n",
      "Done with 09/9\n",
      "Done with 09/12\n",
      "Done with 09/15\n",
      "Done with 09/18\n",
      "Done with 09/21\n",
      "Done with 09/24\n",
      "Done with 09/27\n",
      "Done with 09/30\n",
      "Done with 10/3\n",
      "Error parsing year info - using previous query info\n",
      "Error parsing year info - using previous query info\n",
      "Done with 10/6\n",
      "Error parsing year info - using previous query info\n",
      "Error parsing year info - using previous query info\n",
      "Error parsing year info - using previous query info\n",
      "Done with 10/9\n",
      "Error parsing year info - using previous query info\n",
      "Error parsing year info - using previous query info\n",
      "Error parsing year info - using previous query info\n",
      "Done with 10/12\n",
      "Error parsing year info - using previous query info\n",
      "Error parsing year info - using previous query info\n",
      "Error parsing year info - using previous query info\n",
      "Done with 10/15\n",
      "Error parsing year info - using previous query info\n",
      "Error parsing year info - using previous query info\n",
      "Done with 10/18\n",
      "Done with 10/21\n",
      "Done with 10/24\n",
      "Done with 10/27\n",
      "Done with 10/30\n",
      "Done with 11/3\n",
      "Done with 11/6\n",
      "Done with 11/9\n",
      "Done with 11/12\n",
      "Done with 11/15\n",
      "Done with 11/18\n",
      "Done with 11/21\n",
      "Done with 11/24\n",
      "Done with 11/27\n",
      "Done with 11/30\n",
      "Done with 12/3\n",
      "Done with 12/6\n",
      "Done with 12/9\n",
      "Done with 12/12\n",
      "Done with 12/15\n",
      "Done with 12/18\n",
      "Done with 12/21\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 12/24\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 12/27\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 12/30\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 01/3\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 01/6\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 01/9\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 01/12\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 01/15\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 01/18\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 01/21\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 01/24\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 01/27\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Feb\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ffff9175c7fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0;31m#Skip empty rows and free agents (cols[4].find('a') empty means free agent)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                     \u001b[0mteam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'span'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'tiny'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m                     \u001b[0mplayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "#PPR Version\n",
    "year='2012'\n",
    "\n",
    "#Season starts first week in September, ends at end of December\n",
    "for month in ['09','10','11','12','01']:\n",
    "    for day in range(3,31,3):\n",
    "        for pos in ['wr','rb','te']:\n",
    "            web_add = 'https://web.archive.org/web/%s%s%s/http://www.fantasypros.com/nfl/rankings/ppr-%s.php' % (year,str(month).zfill(2),str(day).zfill(2),pos)\n",
    "\n",
    "            #Check Jan of the next year too\n",
    "            if month=='01':   \n",
    "                web_add = 'https://web.archive.org/web/%s%s%s/http://www.fantasypros.com/nfl/rankings/ppr-%s.php' % (str(int(year)+1),str(month).zfill(2),str(day).zfill(2),pos)\n",
    " \n",
    "            web_html = urlopen(web_add).read()\n",
    "            soup = BeautifulSoup(web_html)\n",
    "\n",
    "            #Check if unavailable issue\n",
    "            #If it's there, retry in 10 seconds\n",
    "            while 'Service Unavailable' in soup.text:\n",
    "                print 'No Server Avaialble.  Trying Again in 10 seconds...'\n",
    "                time.sleep(10)\n",
    "                web_html = urlopen(web_add).read()\n",
    "                soup = BeautifulSoup(web_html)\n",
    "\n",
    "            #Get the week and year of the predictions\n",
    "            title= soup.find(\"title\")\n",
    "            web_week=int(title.text.split(' ')[1])\n",
    "            \n",
    "            #catch week 17 leaking into the start of the year\n",
    "            if (month=='09') and (int(web_week)>10):\n",
    "                print \"Warning: Web week %s found in month 09\" % web_week\n",
    "\n",
    "            \n",
    "            comments=soup.find_all(string=lambda text:isinstance(text,Comment))\n",
    "            if 'FILE ARCHIVED' in soup.find_all(string=lambda text:isinstance(text,Comment))[-1]:            \n",
    "                web_year = comments[-1].split(' ')[11]\n",
    "                web_month = comments[-1].split(' ')[9]\n",
    "                if web_year != year:\n",
    "                    print \"Warning: Web year and Season Year mismatch.  Web month is %s\" % web_month\n",
    "\n",
    "            else:\n",
    "                print 'Error parsing year info - using previous query info' \n",
    "                #this is fine as long as it doesn't happen on the first query\n",
    "              \n",
    "                \n",
    "            #Get the player rankings and injury status\n",
    "            table= soup.find(\"table\", { \"id\" : \"data\"} )\n",
    "\n",
    "            #Skip the first row of the table, since it is header info\n",
    "            rows=table.findAll('tr')\n",
    "            iterrows = iter(rows)\n",
    "            next(iterrows)\n",
    "\n",
    "            #Iterate over reaming rows\n",
    "            for tr in iterrows:\n",
    "\n",
    "                #Find all columns and exctract info\n",
    "                cols = tr.findAll('td')  \n",
    "\n",
    "                #Skip empty rows and free agents (cols[4].find('a') empty means free agent)\n",
    "                if cols[1].find('a').contents:\n",
    "                    team = cols[1].find('span',{'class':'tiny'}).text.split(' ')[0][1:]   \n",
    "                    player = cols[1].find('a').contents[0]\n",
    "\n",
    "                    #If the player isn't in our database, find the closest matching name\n",
    "                    #It's okay if it comes back with bull, since the player + team + season + week\n",
    "                    #combo will prevent it from being entered\n",
    "                    if player not in gameStats['Player'].tolist():\n",
    "                        player = str(nfldb.player_search(db,player)[0])\n",
    "\n",
    "                    rank=cols[0].text\n",
    "                    best_rank=cols[2].text\n",
    "                    worst_rank=cols[3].text\n",
    "                    average_rank=cols[4].text\n",
    "\n",
    "                    #Check for old format where they use an image\n",
    "                    if cols[1].find('img'):\n",
    "                        injury_status=cols[1].find('img').get('title')[0]         \n",
    "                    #Check for the end of year format where they use a red letter instead of img\n",
    "                    elif len(cols[1].findAll('span',{'class':'tiny'}))>1:\n",
    "                        injury_status=cols[1].findAll('span',{'class':'tiny'})[1].text\n",
    "                    else:\n",
    "                        injury_status='H' #H for healthy\n",
    "\n",
    "                    #Use player,team,week,and year to fill in the information in our dataframe        \n",
    "                    selector=( (gameStats.Player==player) & (gameStats.Team ==team) &\\\n",
    "                               (gameStats.SeasonWeek==int(web_week)) & (gameStats.Year==float(year)) )\n",
    "\n",
    "\n",
    "                    #If there is a player,team,season,and week match.. fill in the data\n",
    "                    if len(gameStats[selector])>0: \n",
    "                        gameStats.ix[selector, 'PPR Expert Rank'] = rank         \n",
    "                        gameStats.ix[selector, 'PPR Average Expert Rank'] = average_rank\n",
    "                        gameStats.ix[selector, 'PPR Best Expert Rank']=best_rank\n",
    "                        gameStats.ix[selector, 'PPR Worst Expert Rank']=worst_rank\n",
    "                        gameStats.ix[selector, 'PPR Injury Status']=injury_status\n",
    "                        \n",
    "        print 'Done with %s/%s' % (month,day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gameStats.to_csv('gameStats_withExperts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skipping 2013 since it wasn't acrhived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with 09/3\n",
      "Done with 09/6\n",
      "Done with 09/9\n",
      "Done with 09/12\n",
      "Done with 09/15\n",
      "Done with 09/18\n",
      "Done with 09/21\n",
      "Done with 09/24\n",
      "Done with 09/27\n",
      "Done with 09/30\n",
      "Done with 10/3\n",
      "Done with 10/6\n",
      "Done with 10/9\n",
      "Done with 10/12\n",
      "Done with 10/15\n",
      "Done with 10/18\n",
      "Done with 10/21\n",
      "Done with 10/24\n",
      "Done with 10/27\n",
      "Done with 10/30\n",
      "Done with 11/3\n",
      "Done with 11/6\n",
      "Done with 11/9\n",
      "Done with 11/12\n",
      "Done with 11/15\n",
      "Done with 11/18\n",
      "Done with 11/21\n",
      "Done with 11/24\n",
      "Done with 11/27\n",
      "Done with 11/30\n",
      "Done with 12/3\n",
      "Done with 12/6\n",
      "Done with 12/9\n",
      "Done with 12/12\n",
      "Done with 12/15\n",
      "Done with 12/18\n",
      "Done with 12/21\n",
      "Done with 12/24\n",
      "Done with 12/27\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'WR'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-6c84ebf44d57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;31m#Get the week and year of the predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"title\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mweb_week\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;31m#catch week 17 leaking into the start of the year\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'WR'"
     ]
    }
   ],
   "source": [
    "year='2014'\n",
    "\n",
    "#Season starts first week in September, ends at end of December\n",
    "for month in ['09','10','11','12','01']:\n",
    "    for day in range(3,31,3):\n",
    "        for pos in ['wr','rb','te','qb']:\n",
    "            web_add = 'https://web.archive.org/web/%s%s%s/http://www.fantasypros.com/nfl/rankings/%s.php' % (year,str(month).zfill(2),str(day).zfill(2),pos)\n",
    "\n",
    "            #Check Jan of the next year too\n",
    "            if month=='01':   \n",
    "                web_add = 'https://web.archive.org/web/%s%s%s/http://www.fantasypros.com/nfl/rankings/%s.php' % (str(int(year)+1),str(month).zfill(2),str(day).zfill(2),pos)\n",
    "\n",
    "            web_html = urlopen(web_add).read()\n",
    "            soup = BeautifulSoup(web_html)\n",
    "\n",
    "            #Check if unavailable issue\n",
    "            #If it's there, retry in 10 seconds\n",
    "            while 'Service Unavailable' in soup.text:\n",
    "                print 'No Server Avaialble.  Trying Again in 10 seconds...'\n",
    "                time.sleep(10)\n",
    "                web_html = urlopen(web_add).read()\n",
    "                soup = BeautifulSoup(web_html)\n",
    "\n",
    "            #Get the week and year of the predictions\n",
    "            title= soup.find(\"title\")\n",
    "            web_week=int(title.text.split(' ')[1])\n",
    "\n",
    "            #catch week 17 leaking into the start of the year\n",
    "            if (month=='09') and (int(web_week)>10):\n",
    "                print \"Warning: Web week %s found in month 09\" % web_week\n",
    "            \n",
    "\n",
    "            comments=soup.find_all(string=lambda text:isinstance(text,Comment))\n",
    "            if 'FILE ARCHIVED' in soup.find_all(string=lambda text:isinstance(text,Comment))[-1]:            \n",
    "                web_year = comments[-1].split(' ')[11]\n",
    "                web_month = comments[-1].split(' ')[9]\n",
    "                if web_year != year:\n",
    "                    print \"Warning: Web year and Season Year mismatch.  Web month is %s\" % web_month\n",
    "\n",
    "            else:\n",
    "                print 'Error parsing year info - using previous query info' \n",
    "                #this is fine as long as it doesn't happen on the first query\n",
    "\n",
    "\n",
    "            #Get the player rankings and injury status\n",
    "            table= soup.find(\"table\", { \"id\" : \"data\"} )\n",
    "\n",
    "            #Skip the first row of the table, since it is header info\n",
    "            rows=table.findAll('tr')\n",
    "            iterrows = iter(rows)\n",
    "            next(iterrows)\n",
    "\n",
    "            #Iterate over reaming rows\n",
    "            for tr in iterrows:\n",
    "\n",
    "                #Find all columns and exctract info\n",
    "                cols = tr.findAll('td')  \n",
    "\n",
    "                if len(cols)>1:\n",
    "\n",
    "                    #Skip empty rows and free agents (cols[4].find('a') empty means free agent)\n",
    "                    if cols[1].find('a').contents:\n",
    "                        team = cols[1].find('small').text.split(')')[0].split('(')[-1]   \n",
    "                        player = cols[1].find('a').contents[0]\n",
    "\n",
    "                        #If the player isn't in our database, find the closest matching name\n",
    "                        #It's okay if it comes back with bull, since the player + team + season + week\n",
    "                        #combo will prevent it from being entered\n",
    "                        if player not in gameStats['Player'].tolist():\n",
    "                            player = str(nfldb.player_search(db,player)[0])\n",
    "\n",
    "                        rank=cols[0].text\n",
    "                        best_rank=cols[2].text\n",
    "                        worst_rank=cols[3].text\n",
    "                        average_rank=cols[4].text\n",
    "\n",
    "                        #Check for injury info\n",
    "                        if cols[1].find('div',{'class':'pull-right'}):\n",
    "                            injury_status=cols[1].find('div',{'class':'pull-right'}).text[0]        \n",
    "                        else:\n",
    "                            injury_status='H' #H for healthy\n",
    "\n",
    "                        #Use player,team,week,and year to fill in the information in our dataframe        \n",
    "                        selector=( (gameStats.Player==player) & (gameStats.Team ==team) &\\\n",
    "                                   (gameStats.SeasonWeek==int(web_week)) & (gameStats.Year==float(year)) )\n",
    "\n",
    "\n",
    "                        #If there is a player,team,season,and week match.. fill in the data\n",
    "                        if len(gameStats[selector])>0: \n",
    "                            gameStats.ix[selector, 'Expert Rank'] = rank         \n",
    "                            gameStats.ix[selector, 'Average Expert Rank'] = average_rank\n",
    "                            gameStats.ix[selector, 'Best Expert Rank']=best_rank\n",
    "                            gameStats.ix[selector, 'Worst Expert Rank']=worst_rank\n",
    "                            gameStats.ix[selector, 'Injury Status']=injury_status\n",
    "                        \n",
    "        print 'Done with %s/%s' % (month,day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gameStats.to_csv('gameStats_withExperts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with 10/3\n",
      "Done with 10/6\n",
      "Done with 10/9\n",
      "Done with 10/12\n",
      "Done with 10/15\n",
      "Done with 10/18\n",
      "Done with 10/21\n",
      "Done with 10/24\n",
      "Done with 10/27\n",
      "Done with 10/30\n",
      "Done with 11/3\n",
      "Done with 11/6\n",
      "Done with 11/9\n",
      "Done with 11/12\n",
      "Done with 11/15\n",
      "Done with 11/18\n",
      "Done with 11/21\n",
      "Done with 11/24\n",
      "Done with 11/27\n",
      "Done with 11/30\n",
      "Done with 12/3\n",
      "Done with 12/6\n",
      "Done with 12/9\n",
      "Done with 12/12\n",
      "Done with 12/15\n",
      "Done with 12/18\n",
      "Done with 12/21\n",
      "Done with 12/24\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'WR'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-14ec8a0c7eab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;31m#Get the week and year of the predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"title\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mweb_week\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;31m#catch week 17 leaking into the start of the year\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'WR'"
     ]
    }
   ],
   "source": [
    "#2014 basically doesn't exist..have to skip 09... PPR Version\n",
    "year='2014'\n",
    "\n",
    "#Season starts first week in September, ends at end of December\n",
    "for month in ['10','11','12','01']:\n",
    "    for day in range(3,31,3):\n",
    "        for pos in ['wr','rb','te']:\n",
    "            web_add = 'https://web.archive.org/web/%s%s%s/http://www.fantasypros.com/nfl/rankings/ppr-%s.php' % (year,str(month).zfill(2),str(day).zfill(2),pos)\n",
    "\n",
    "            #Check Jan of the next year too\n",
    "            if month=='01':   \n",
    "                web_add = 'https://web.archive.org/web/%s%s%s/http://www.fantasypros.com/nfl/rankings/ppr-%s.php' % (str(int(year)+1),str(month).zfill(2),str(day).zfill(2),pos)\n",
    "\n",
    "            web_html = urlopen(web_add).read()\n",
    "            soup = BeautifulSoup(web_html)\n",
    "\n",
    "            #Check if unavailable issue\n",
    "            #If it's there, retry in 10 seconds\n",
    "            while 'Service Unavailable' in soup.text:\n",
    "                print 'No Server Avaialble.  Trying Again in 10 seconds...'\n",
    "                time.sleep(10)\n",
    "                web_html = urlopen(web_add).read()\n",
    "                soup = BeautifulSoup(web_html)\n",
    "\n",
    "            #Get the week and year of the predictions\n",
    "            title= soup.find(\"title\")\n",
    "            web_week=int(title.text.split(' ')[1])\n",
    "\n",
    "            #catch week 17 leaking into the start of the year\n",
    "            if (month=='09') and (int(web_week)>10):\n",
    "                print \"Warning: Web week %s found in month 09\" % web_week\n",
    "\n",
    "\n",
    "\n",
    "            comments=soup.find_all(string=lambda text:isinstance(text,Comment))\n",
    "            if 'FILE ARCHIVED' in soup.find_all(string=lambda text:isinstance(text,Comment))[-1]:            \n",
    "                web_year = comments[-1].split(' ')[11]\n",
    "                web_month = comments[-1].split(' ')[9]\n",
    "                if web_year != year:\n",
    "                    print \"Warning: Web year and Season Year mismatch.  Web month is %s\" % web_month\n",
    "\n",
    "            else:\n",
    "                print 'Error parsing year info - using previous query info' \n",
    "                #this is fine as long as it doesn't happen on the first query\n",
    "\n",
    "\n",
    "            #Get the player rankings and injury status\n",
    "            table= soup.find(\"table\", { \"id\" : \"data\"} )\n",
    "\n",
    "            #Skip the first row of the table, since it is header info\n",
    "            rows=table.findAll('tr')\n",
    "            iterrows = iter(rows)\n",
    "            next(iterrows)\n",
    "\n",
    "            #Iterate over reaming rows\n",
    "            for tr in iterrows:\n",
    "\n",
    "                #Find all columns and exctract info\n",
    "                cols = tr.findAll('td')  \n",
    "\n",
    "                if len(cols)>1:\n",
    "\n",
    "                    #Skip empty rows and free agents (cols[4].find('a') empty means free agent)\n",
    "                    if cols[1].find('a').contents:\n",
    "                        team = cols[1].find('small').text.split(')')[0].split('(')[-1]   \n",
    "                        player = cols[1].find('a').contents[0]\n",
    "\n",
    "                        #If the player isn't in our database, find the closest matching name\n",
    "                        #It's okay if it comes back with bull, since the player + team + season + week\n",
    "                        #combo will prevent it from being entered\n",
    "                        if player not in gameStats['Player'].tolist():\n",
    "                            player = str(nfldb.player_search(db,player)[0])\n",
    "\n",
    "                        rank=cols[0].text\n",
    "                        best_rank=cols[2].text\n",
    "                        worst_rank=cols[3].text\n",
    "                        average_rank=cols[4].text\n",
    "\n",
    "                        #Check for injury info\n",
    "                        if cols[1].find('div',{'class':'pull-right'}):\n",
    "                            injury_status=cols[1].find('div',{'class':'pull-right'}).text[0]        \n",
    "                        else:\n",
    "                            injury_status='H' #H for healthy\n",
    "\n",
    "                        #Use player,team,week,and year to fill in the information in our dataframe        \n",
    "                        selector=( (gameStats.Player==player) & (gameStats.Team ==team) &\\\n",
    "                                   (gameStats.SeasonWeek==int(web_week)) & (gameStats.Year==float(year)) )\n",
    "\n",
    "\n",
    "                        #If there is a player,team,season,and week match.. fill in the data\n",
    "                        if len(gameStats[selector])>0: \n",
    "                            gameStats.ix[selector, 'PPR Expert Rank'] = rank         \n",
    "                            gameStats.ix[selector, 'PPR Average Expert Rank'] = average_rank\n",
    "                            gameStats.ix[selector, 'PPR Best Expert Rank']=best_rank\n",
    "                            gameStats.ix[selector, 'PPR Worst Expert Rank']=worst_rank\n",
    "                            gameStats.ix[selector, 'PPR Injury Status']=injury_status\n",
    "                            \n",
    "        print 'Done with %s/%s' % (month,day)                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gameStats.to_csv('gameStats_withExperts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with 09/3\n",
      "Done with 09/6\n",
      "Done with 09/9\n",
      "Done with 09/12\n",
      "Done with 09/15\n",
      "Done with 09/18\n",
      "Done with 09/21\n",
      "Done with 09/24\n",
      "Done with 09/27\n",
      "Done with 09/30\n",
      "Done with 10/3\n",
      "Done with 10/6\n",
      "Done with 10/9\n",
      "Done with 10/12\n",
      "Done with 10/15\n",
      "Done with 10/18\n",
      "Done with 10/21\n",
      "Done with 10/24\n",
      "Done with 10/27\n",
      "Done with 10/30\n",
      "Done with 11/3\n",
      "Done with 11/6\n",
      "Done with 11/9\n",
      "Done with 11/12\n",
      "Done with 11/15\n",
      "Done with 11/18\n",
      "Done with 11/21\n",
      "Done with 11/24\n",
      "Done with 11/27\n",
      "Error parsing year info - using previous query info\n",
      "Done with 11/30\n",
      "Error parsing year info - using previous query info\n",
      "Error parsing year info - using previous query info\n",
      "Error parsing year info - using previous query info\n",
      "Error parsing year info - using previous query info\n",
      "Done with 12/3\n",
      "Error parsing year info - using previous query info\n",
      "Error parsing year info - using previous query info\n",
      "Error parsing year info - using previous query info\n",
      "Error parsing year info - using previous query info\n",
      "Done with 12/6\n",
      "Error parsing year info - using previous query info\n",
      "Done with 12/9\n",
      "Done with 12/12\n",
      "Done with 12/15\n",
      "Done with 12/18\n",
      "Done with 12/21\n",
      "Done with 12/24\n",
      "Done with 12/27\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 12/30\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 01/3\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 01/6\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'WR'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-8b6108c2fd46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;31m#Get the week and year of the predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"title\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mweb_week\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;31m#catch week 17 leaking into the start of the year\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'WR'"
     ]
    }
   ],
   "source": [
    "year='2015'\n",
    "\n",
    "#Season starts first week in September, ends at end of December\n",
    "for month in ['09','10','11','12','01']:\n",
    "    for day in range(3,31,3):\n",
    "        for pos in ['wr','rb','te','qb']:\n",
    "            web_add = 'https://web.archive.org/web/%s%s%s/http://www.fantasypros.com/nfl/rankings/%s.php' % (year,str(month).zfill(2),str(day).zfill(2),pos)\n",
    "\n",
    "            #Check Jan of the next year too\n",
    "            if month=='01':   \n",
    "                web_add = 'https://web.archive.org/web/%s%s%s/http://www.fantasypros.com/nfl/rankings/%s.php' % (str(int(year)+1),str(month).zfill(2),str(day).zfill(2),pos)\n",
    " \n",
    "            web_html = urlopen(web_add).read()\n",
    "            soup = BeautifulSoup(web_html)\n",
    "\n",
    "            #Check if unavailable issue\n",
    "            #If it's there, retry in 10 seconds\n",
    "            while 'Service Unavailable' in soup.text:\n",
    "                print 'No Server Avaialble.  Trying Again in 10 seconds...'\n",
    "                time.sleep(10)\n",
    "                web_html = urlopen(web_add).read()\n",
    "                soup = BeautifulSoup(web_html)\n",
    "\n",
    "            #Get the week and year of the predictions\n",
    "            title= soup.find(\"title\")\n",
    "            web_week=int(title.text.split(' ')[1])\n",
    "\n",
    "            #catch week 17 leaking into the start of the year\n",
    "            if (month=='09') and (int(web_week)>10):\n",
    "                print \"Warning: Web week %s found in month 09\" % web_week\n",
    "            \n",
    "            \n",
    "            comments=soup.find_all(string=lambda text:isinstance(text,Comment))\n",
    "            if 'FILE ARCHIVED' in soup.find_all(string=lambda text:isinstance(text,Comment))[-1]:            \n",
    "                web_year = comments[-1].split(' ')[11]\n",
    "                web_month = comments[-1].split(' ')[9]\n",
    "                if web_year != year:\n",
    "                    print \"Warning: Web year and Season Year mismatch.  Web month is %s\" % web_month\n",
    "\n",
    "            else:\n",
    "                print 'Error parsing year info - using previous query info' \n",
    "                #this is fine as long as it doesn't happen on the first query\n",
    "\n",
    "\n",
    "\n",
    "            #Get the player rankings and injury status\n",
    "            table= soup.find(\"table\", { \"id\" : \"data\"} )\n",
    "\n",
    "            #Skip the first row of the table, since it is header info\n",
    "            rows=table.findAll('tr')\n",
    "            iterrows = iter(rows)\n",
    "            next(iterrows)\n",
    "\n",
    "            #Iterate over reaming rows\n",
    "            for tr in iterrows:\n",
    "\n",
    "                #Find all columns and exctract info\n",
    "                cols = tr.findAll('td')  \n",
    "                \n",
    "                if len(cols)>1:\n",
    "\n",
    "                    #Deal with the addition of the opponent column in second week\n",
    "                    if len(cols)==6:\n",
    "                        first_stat_col=2\n",
    "                    elif len(cols)==7:\n",
    "                        first_stat_col=3\n",
    "\n",
    "\n",
    "                    #Skip empty rows and free agents (cols[4].find('a') empty means free agent)\n",
    "                    if cols[1].find('a').contents:\n",
    "                        team = cols[1].find('small').text.split(' ')[0] \n",
    "                        player = cols[1].find('a').contents[0]\n",
    "\n",
    "                        #If the player isn't in our database, find the closest matching name\n",
    "                        #It's okay if it comes back with bull, since the player + team + season + week\n",
    "                        #combo will prevent it from being entered\n",
    "                        if player not in gameStats['Player'].tolist():\n",
    "                            player = str(nfldb.player_search(db,player)[0])\n",
    "\n",
    "                        rank=cols[0].text\n",
    "                        best_rank=cols[first_stat_col].text\n",
    "                        worst_rank=cols[first_stat_col+1].text\n",
    "                        average_rank=cols[first_stat_col+2].text\n",
    "\n",
    "                        #Check for injury info in the original format of page\n",
    "                        if cols[1].find('div',{'class':'pull-right'}):                        \n",
    "                            if cols[1].find('div',{'class':'pull-right'}).text==u'\\xa0':\n",
    "                                injury_status='H'\n",
    "                            else:\n",
    "                                injury_status=cols[1].find('div',{'class':'pull-right'}).text[0] \n",
    "                        #Check updated format of the page\n",
    "                        elif cols[1].find('small',{'class':'dl'}):                                                        \n",
    "                            injury_status=cols[1].find('small',{'class':'dl'}).text[0]\n",
    "                        else:\n",
    "                            injury_status='H' #H for healthy\n",
    "\n",
    "\n",
    "                        #Use player,team,week,and year to fill in the information in our dataframe        \n",
    "                        selector=( (gameStats.Player==player) & (gameStats.Team ==team) &\\\n",
    "                                   (gameStats.SeasonWeek==int(web_week)) & (gameStats.Year==float(year)) )\n",
    "\n",
    "                        #If there is a player,team,season,and week match.. fill in the data\n",
    "                        if len(gameStats[selector])>0: \n",
    "                            gameStats.ix[selector, 'Expert Rank'] = rank         \n",
    "                            gameStats.ix[selector, 'Average Expert Rank'] = average_rank\n",
    "                            gameStats.ix[selector, 'Best Expert Rank']=best_rank\n",
    "                            gameStats.ix[selector, 'Worst Expert Rank']=worst_rank\n",
    "                            gameStats.ix[selector, 'Injury Status']=injury_status\n",
    "                        \n",
    "        print 'Done with %s/%s' % (month,day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gameStats.to_csv('gameStats_withExperts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with 09/3\n",
      "Done with 09/6\n",
      "Done with 09/9\n",
      "Done with 09/12\n",
      "Done with 09/15\n",
      "Done with 09/18\n",
      "Done with 09/21\n",
      "Done with 09/24\n",
      "Done with 09/27\n",
      "Done with 09/30\n",
      "Done with 10/3\n",
      "Done with 10/6\n",
      "Done with 10/9\n",
      "Done with 10/12\n",
      "Done with 10/15\n",
      "Done with 10/18\n",
      "Done with 10/21\n",
      "Done with 10/24\n",
      "Done with 10/27\n",
      "Done with 10/30\n",
      "Done with 11/3\n",
      "Done with 11/6\n",
      "Done with 11/9\n",
      "Done with 11/12\n",
      "Done with 11/15\n",
      "Done with 11/18\n",
      "Done with 11/21\n",
      "Done with 11/24\n",
      "Done with 11/27\n",
      "Done with 11/30\n",
      "Done with 12/3\n",
      "Done with 12/6\n",
      "Done with 12/9\n",
      "Done with 12/12\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 12/15\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 12/18\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 12/21\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 12/24\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 12/27\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 12/30\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n",
      "Done with 01/3\n",
      "Warning: Web year and Season Year mismatch.  Web month is Jan\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'TE'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-68f27bf985d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;31m#Get the week and year of the predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"title\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mweb_week\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;31m#catch week 17 leaking into the start of the year\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'TE'"
     ]
    }
   ],
   "source": [
    "#PPR Version\n",
    "year='2015'\n",
    "\n",
    "#Season starts first week in September, ends at end of December\n",
    "for month in ['09','10','11','12','01']:\n",
    "    for day in range(3,31,3):\n",
    "        for pos in ['wr','rb','te']:\n",
    "            web_add = 'https://web.archive.org/web/%s%s%s/http://www.fantasypros.com/nfl/rankings/ppr-%s.php' % (year,str(month).zfill(2),str(day).zfill(2),pos)\n",
    "\n",
    "            #Check Jan of the next year too\n",
    "            if month=='01':   \n",
    "                web_add = 'https://web.archive.org/web/%s%s%s/http://www.fantasypros.com/nfl/rankings/ppr-%s.php' % (str(int(year)+1),str(month).zfill(2),str(day).zfill(2),pos)\n",
    " \n",
    "            web_html = urlopen(web_add).read()\n",
    "            soup = BeautifulSoup(web_html)\n",
    "\n",
    "            #Check if unavailable issue\n",
    "            #If it's there, retry in 10 seconds\n",
    "            while 'Service Unavailable' in soup.text:\n",
    "                print 'No Server Avaialble.  Trying Again in 10 seconds...'\n",
    "                time.sleep(10)\n",
    "                web_html = urlopen(web_add).read()\n",
    "                soup = BeautifulSoup(web_html)\n",
    "\n",
    "            #Get the week and year of the predictions\n",
    "            title= soup.find(\"title\")\n",
    "            web_week=int(title.text.split(' ')[1])\n",
    "\n",
    "            #catch week 17 leaking into the start of the year\n",
    "            if (month=='09') and (int(web_week)>10):\n",
    "                print \"Warning: Web week %s found in month 09\" % web_week\n",
    "            \n",
    "            \n",
    "            comments=soup.find_all(string=lambda text:isinstance(text,Comment))\n",
    "            if 'FILE ARCHIVED' in soup.find_all(string=lambda text:isinstance(text,Comment))[-1]:            \n",
    "                web_year = comments[-1].split(' ')[11]\n",
    "                web_month = comments[-1].split(' ')[9]\n",
    "                if web_year != year:\n",
    "                    print \"Warning: Web year and Season Year mismatch.  Web month is %s\" % web_month\n",
    "\n",
    "            else:\n",
    "                print 'Error parsing year info - using previous query info' \n",
    "                #this is fine as long as it doesn't happen on the first query\n",
    "\n",
    "\n",
    "            #Get the player rankings and injury status\n",
    "            table= soup.find(\"table\", { \"id\" : \"data\"} )\n",
    "\n",
    "            #Skip the first row of the table, since it is header info\n",
    "            rows=table.findAll('tr')\n",
    "            iterrows = iter(rows)\n",
    "            next(iterrows)\n",
    "\n",
    "            #Iterate over reaming rows\n",
    "            for tr in iterrows:\n",
    "\n",
    "                #Find all columns and exctract info\n",
    "                cols = tr.findAll('td')  \n",
    "                \n",
    "                if len(cols)>1:\n",
    "\n",
    "                    #Deal with the addition of the opponent column in second week\n",
    "                    if len(cols)==6:\n",
    "                        first_stat_col=2\n",
    "                    elif len(cols)==7:\n",
    "                        first_stat_col=3\n",
    "\n",
    "\n",
    "                    #Skip empty rows and free agents (cols[4].find('a') empty means free agent)\n",
    "                    if cols[1].find('a').contents:\n",
    "                        team = cols[1].find('small').text.split(' ')[0] \n",
    "                        player = cols[1].find('a').contents[0]\n",
    "\n",
    "                        #If the player isn't in our database, find the closest matching name\n",
    "                        #It's okay if it comes back with bull, since the player + team + season + week\n",
    "                        #combo will prevent it from being entered\n",
    "                        if player not in gameStats['Player'].tolist():\n",
    "                            player = str(nfldb.player_search(db,player)[0])\n",
    "\n",
    "                        rank=cols[0].text\n",
    "                        best_rank=cols[first_stat_col].text\n",
    "                        worst_rank=cols[first_stat_col+1].text\n",
    "                        average_rank=cols[first_stat_col+2].text\n",
    "\n",
    "                        #Check for injury info in the original format of page\n",
    "                        if cols[1].find('div',{'class':'pull-right'}):                        \n",
    "                            if cols[1].find('div',{'class':'pull-right'}).text==u'\\xa0':\n",
    "                                injury_status='H'\n",
    "                            else:\n",
    "                                injury_status=cols[1].find('div',{'class':'pull-right'}).text[0] \n",
    "                        #Check updated format of the page\n",
    "                        elif cols[1].find('small',{'class':'dl'}):                                                        \n",
    "                            injury_status=cols[1].find('small',{'class':'dl'}).text[0]\n",
    "                        else:\n",
    "                            injury_status='H' #H for healthy\n",
    "\n",
    "\n",
    "                          #Use player,team,week,and year to fill in the information in our dataframe        \n",
    "                        selector=( (gameStats.Player==player) & (gameStats.Team ==team) &\\\n",
    "                                   (gameStats.SeasonWeek==int(web_week)) & (gameStats.Year==float(year)) )\n",
    "\n",
    "                        #If there is a player,team,season,and week match.. fill in the data\n",
    "                        if len(gameStats[selector])>0: \n",
    "                            gameStats.ix[selector, 'PPR Expert Rank'] = rank         \n",
    "                            gameStats.ix[selector, 'PPR Average Expert Rank'] = average_rank\n",
    "                            gameStats.ix[selector, 'PPR Best Expert Rank']=best_rank\n",
    "                            gameStats.ix[selector, 'PPR Worst Expert Rank']=worst_rank\n",
    "                            gameStats.ix[selector, 'PPR Injury Status']=injury_status\n",
    "                        \n",
    "        print 'Done with %s/%s' % (month,day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gameStats.to_csv('gameStats_withExperts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py27]",
   "language": "python",
   "name": "Python [py27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
