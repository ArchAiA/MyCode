{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "layout: post\n",
    "title: PoGo Series&#58; Statistical Analysis of Data\n",
    "comments: true\n",
    "---\n",
    "\n",
    "Measuring the dominance of each time in each state while properly accounting for statistical and systematic errors.\n",
    "\n",
    "\n",
    "<!--more-->\n",
    "\n",
    "TABLE OF CONTENTS\n",
    "\n",
    "\n",
    "Welcome to the second-to-last post in our Pokemon Go analysis series.  Last time, we trained a sentiment analyzer that will allow us to remove negative tweets from our collection.  In this post, we'll use this analyzer to clean up our data and determine the dominance of each Pokemon Go team in each state.  Once we've cleaned the data, we'll count the number of tweets referencing each Pokemon Go team to determine the dominance of each team in every state.  Along the way, we'll discuss how to properly account for statistical and systematic errors in our measurement.\n",
    "\n",
    "\n",
    "We'll cover the following topics:\n",
    "\n",
    "1. [Cleaning the data](#cleaning)\n",
    "2. [Finding the location of each tweet](#location)\n",
    "3. [Measuring team dominance in each state](#dominance)\n",
    "4. [Statistical analysis of the data](#stats)\n",
    "\n",
    "\n",
    "# <a name=\"cleaning\"></a> Cleaning the Data\n",
    "\n",
    "Before we begin, we'll need to load the our collection of tweets into Pandas.  We already did this in our last post, and saved to the result to a csv file. We can load that csv file with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This is needed to load our csv\n",
    "import pandas as pd\n",
    "\n",
    "#We'll also use numpy to do some math later\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screenName</th>\n",
       "      <th>userId</th>\n",
       "      <th>text</th>\n",
       "      <th>location</th>\n",
       "      <th>multi-team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>desmond_ayala</td>\n",
       "      <td>2.953472e+09</td>\n",
       "      <td>Which pokemon go team did y'all chose? #valor</td>\n",
       "      <td>Caldwell, ID</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aphrospice</td>\n",
       "      <td>1.629086e+07</td>\n",
       "      <td>#Magikarp practicing his struggle skills in th...</td>\n",
       "      <td>Brooklyn, NY</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABellgowan</td>\n",
       "      <td>1.681036e+09</td>\n",
       "      <td>Pokemon Go is taking over my life #TeamInstinct</td>\n",
       "      <td>Bixby, OK</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JangoSnow</td>\n",
       "      <td>1.057434e+07</td>\n",
       "      <td>Go Team Instinct! I like underdogs. :)  https:...</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EmberLighta2</td>\n",
       "      <td>7.513920e+17</td>\n",
       "      <td>#TeamMystic has total control of Niagara Falls!!</td>\n",
       "      <td>Niagara Falls, NY</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      screenName        userId  \\\n",
       "0  desmond_ayala  2.953472e+09   \n",
       "1     aphrospice  1.629086e+07   \n",
       "2     ABellgowan  1.681036e+09   \n",
       "3      JangoSnow  1.057434e+07   \n",
       "4   EmberLighta2  7.513920e+17   \n",
       "\n",
       "                                                text           location  \\\n",
       "0      Which pokemon go team did y'all chose? #valor       Caldwell, ID   \n",
       "1  #Magikarp practicing his struggle skills in th...       Brooklyn, NY   \n",
       "2    Pokemon Go is taking over my life #TeamInstinct          Bixby, OK   \n",
       "3  Go Team Instinct! I like underdogs. :)  https:...    Los Angeles, CA   \n",
       "4   #TeamMystic has total control of Niagara Falls!!  Niagara Falls, NY   \n",
       "\n",
       "  multi-team  \n",
       "0      False  \n",
       "1      False  \n",
       "2      False  \n",
       "3      False  \n",
       "4      False  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the full collection of PoGo tweets\n",
    "PoGo_tweets = pd.read_csv('PoGo_Sentiment_AllTweets.csv')\n",
    "PoGo_tweets.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "PoGo_tweets.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the csv file has already had all tweets that reference multiple teams removed, since we decided it would be too hard to identify which team the Twitter user was on from such tweets. \n",
    "\n",
    "We'd like to remove any negatively-toned tweets from our collection so that we can assume any remaining tweets about the team indicates that the Twitter user is a member of that team.  We can do so by applying the sentiment analyzer that we developed in our last post.  First, we use `pickle` to load the sentiment analyzer and feature list that we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load the classifier\n",
    "import pickle\n",
    "f = open('PoGo_tweet_classifier.pickle', 'rb')\n",
    "classifier = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "#load the list of features used in the classifier\n",
    "with open('PoGo_classifier_feats.pickle', 'rb') as f:\n",
    "    word_features = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also need to use the `filter_tweets` and `extract_features` functions that we wrote for our sentiment analyzer.  In this case, I've slightly modified the `filter_tweets` function &mdash; it now produces a list of filtered unigrams and bigrams for each tweet instead of a tuple, since we have no manually labeled sentiment to pair with such a list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load the required modules\n",
    "import nltk\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "import itertools\n",
    "import string\n",
    "\n",
    "\n",
    "#Set of punctuation to exclude from unigrams and bigrams\n",
    "exclude = set(string.punctuation)\n",
    "\n",
    "#List of team-identifying words to exclude from unigrams and bigrams\n",
    "excluded_words = ['teammystic','mystic','teamblue','blue',\\\n",
    "                  'teaminstinct','instinct','teamyellow','yellow',\\\n",
    "                  'teamvalor','valor','teamred','red']\n",
    "\n",
    "\n",
    "#Function that provides a list of filtered unigrams and bigrams from each tweet\n",
    "def filter_tweets(tweet_text):\n",
    "    words_filtered=[]\n",
    "\n",
    "    #For each word in the tweet, filter on our feature requirements.\n",
    "    for word in tweet_text.split(): \n",
    "\n",
    "        #Remove punctuation\n",
    "        word = ''.join(ch for ch in word if ch not in exclude)\n",
    "\n",
    "        #Remove one letter words\n",
    "        if len(word) >= 1: \n",
    "\n",
    "                #treat URLs the same\n",
    "                if word[:4] == 'http':\n",
    "                    word='http'\n",
    "\n",
    "                #remove hashtags\n",
    "                if word[0] == '#': \n",
    "                    word=word[1:]\n",
    "\n",
    "                #remove team identifiers\n",
    "                if (word.lower() not in excluded_words):\n",
    "\n",
    "                    #require lower case\n",
    "                    words_filtered.append(word.lower()) \n",
    "    \n",
    "    #If the word list contains only duplicates of one word, it causes problems for bigram finder\n",
    "    #In this case, don't bother trying to find bigrams, just find the unigram since there are no bigrams anyway\n",
    "    if len(set(words_filtered)) == 1:\n",
    "        tweet_feats = words_filtered[0]\n",
    "    else:  \n",
    "        #Identify top 200 bigams in the filtered word list using chi_sq measure of importance\n",
    "        bigram_finder = BigramCollocationFinder.from_words(words_filtered)\n",
    "        bigrams = bigram_finder.nbest(BigramAssocMeasures.chi_sq, 200)  \n",
    "\n",
    "        tweet_feats = [ngram for ngram in itertools.chain(words_filtered, bigrams)]\n",
    "\n",
    "    return tweet_feats\n",
    "\n",
    "\n",
    "#Feature extractor - determines which word features are in each tweet\n",
    "def extract_features(filtered_tweet):\n",
    "\n",
    "    #list of unigrams and bigrams in the tweet\n",
    "    filtered_tweet_words = set(filtered_tweet)\n",
    "    \n",
    "    #Define a features dictionary\n",
    "    features = {}\n",
    "\n",
    "    #Loop of all word features\n",
    "    for word in word_features:\n",
    "        \n",
    "        #Set 'contains(word_feature)' as a key in the dictionary\n",
    "        #Set the value for that key to True or False\n",
    "        features['contains(%s)' % str(word)] = (word in filtered_tweet_words)\n",
    "\n",
    "    #Return the final features dictionary for that tweet\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To classify the sentiment of eah tweets in our collection, we first apply the `filter_tweets` function to extract the filtered unigrams and bigrams from the tweet.  We use that list of unigrams and bigrams to evaluate the `contains(word_feature)` statements which we used as features for our sentiment analyzer.  Finally, we pass the feature values to our sentiment analyzer and place the result in a new \"sentiment\" column in our data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Classifying tweets\n",
    "def ClassifyTweets(dFrame):\n",
    "    for row in range(len(dFrame)):\n",
    "        \n",
    "        #Get filtered unigrams and bigrams\n",
    "        filtered_text = filter_tweets(dFrame.ix[row,'text'])\n",
    "        \n",
    "        #Evaluate the contains(word) statements\n",
    "        tweet_feats = extract_features(filtered_text)\n",
    "        \n",
    "        #Add result to new sentimenet column in the dataframe\n",
    "        dFrame.ix[row,'sentiment']=classifier.classify(tweet_feats)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screenName</th>\n",
       "      <th>userId</th>\n",
       "      <th>text</th>\n",
       "      <th>location</th>\n",
       "      <th>multi-team</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>desmond_ayala</td>\n",
       "      <td>2.953472e+09</td>\n",
       "      <td>Which pokemon go team did y'all chose? #valor</td>\n",
       "      <td>Caldwell, ID</td>\n",
       "      <td>False</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aphrospice</td>\n",
       "      <td>1.629086e+07</td>\n",
       "      <td>#Magikarp practicing his struggle skills in th...</td>\n",
       "      <td>Brooklyn, NY</td>\n",
       "      <td>False</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABellgowan</td>\n",
       "      <td>1.681036e+09</td>\n",
       "      <td>Pokemon Go is taking over my life #TeamInstinct</td>\n",
       "      <td>Bixby, OK</td>\n",
       "      <td>False</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JangoSnow</td>\n",
       "      <td>1.057434e+07</td>\n",
       "      <td>Go Team Instinct! I like underdogs. :)  https:...</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>False</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EmberLighta2</td>\n",
       "      <td>7.513920e+17</td>\n",
       "      <td>#TeamMystic has total control of Niagara Falls!!</td>\n",
       "      <td>Niagara Falls, NY</td>\n",
       "      <td>False</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      screenName        userId  \\\n",
       "0  desmond_ayala  2.953472e+09   \n",
       "1     aphrospice  1.629086e+07   \n",
       "2     ABellgowan  1.681036e+09   \n",
       "3      JangoSnow  1.057434e+07   \n",
       "4   EmberLighta2  7.513920e+17   \n",
       "\n",
       "                                                text           location  \\\n",
       "0      Which pokemon go team did y'all chose? #valor       Caldwell, ID   \n",
       "1  #Magikarp practicing his struggle skills in th...       Brooklyn, NY   \n",
       "2    Pokemon Go is taking over my life #TeamInstinct          Bixby, OK   \n",
       "3  Go Team Instinct! I like underdogs. :)  https:...    Los Angeles, CA   \n",
       "4   #TeamMystic has total control of Niagara Falls!!  Niagara Falls, NY   \n",
       "\n",
       "  multi-team sentiment  \n",
       "0      False  positive  \n",
       "1      False  positive  \n",
       "2      False  positive  \n",
       "3      False  positive  \n",
       "4      False  positive  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ClassifyTweets(PoGo_tweets)\n",
    "PoGo_tweets.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a state in the US has a lot of Twitter users we'll have plenty of tweets for our team dominance measurement.  In this case, removing tweets that our sentiment analyzer has identified as negative will reduce the total error on our measurement.  However, if a particular state has very few tweets about each Pokemon Go team, our sentiment analyzer will reduce our already small sample size.  In turn, this will increase the total error on our team dominance measurement.  I'll explain why this is the case in the upcoming [statistical analysis](#stats) sections, but for now it is sufficient to know that we will not always want to remove the negative tweets from our data set.  Therefore, we must create two branches of our data frame &mdash; one in which we do remove negative tweets, and one in which we do not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Creating a new data frame where we do not apply sentiment analysis\n",
    "PoGo_tweets_nosenti = PoGo_tweets\n",
    "\n",
    "#Applying the positive sentiment restriction on the original dataframe\n",
    "PoGo_tweets = PoGo_tweets[PoGo_tweets['sentiment'] == 'positive']\n",
    "PoGo_tweets = PoGo_tweets.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll want to require that each tweet is coming from a unique user.  If there happens to be a Twitter addict who Tweets about their Pokemon Go team every hour, we don't want to count them as a member of that team multiple times.  We can ensure this doesn't happen by indicating the first tweet from each user in a new column of our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def FindUniqueUsers(dFrame):\n",
    "    unique_users=[]\n",
    "    \n",
    "    #Loop through the tweets in our dataframe\n",
    "    for row in range(len(dFrame)):\n",
    "        \n",
    "        #If we have already seen this Twitter user, flag the tweet as a repeat\n",
    "        if dFrame.ix[row,'screenName'] in unique_users:\n",
    "            dFrame.ix[row,'repeatUser'] = True\n",
    "            \n",
    "        #Otherwise, add the user to a list so we can identify if they tweet again \n",
    "        else:\n",
    "            dFrame.ix[row,'repeatUser'] = False\n",
    "            unique_users.append(dFrame.ix[row,'screenName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Apply the unique user function to both of our data frames\n",
    "FindUniqueUsers(PoGo_tweets_nosenti)\n",
    "FindUniqueUsers(PoGo_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Remove all but the first tweet from each user in our data frames\n",
    "PoGo_tweets = PoGo_tweets[PoGo_tweets['repeatUser'] == False]\n",
    "PoGo_tweets_nosenti = PoGo_tweets_nosenti[PoGo_tweets_nosenti['repeatUser'] == False]\n",
    "\n",
    "#Reindex the data frames\n",
    "PoGo_tweets = PoGo_tweets.reset_index(drop=True)\n",
    "PoGo_tweets_nosenti = PoGo_tweets_nosenti.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> <a name=\"location\"></a> Finding the location of each tweet </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have removed multi-team tweets, negatively-toned tweets, and repeated tweets from the same user from our collection, we are ready to count the number of tweets about each Pokemon Go team in each state.  First, we need to determine which state each tweet came from.  The location column of our data frame almost does this for us, but as you can see below, some tweets have location information in the format `State, Country`, while others have location information in the format `City, State Abbreviation`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screenName</th>\n",
       "      <th>userId</th>\n",
       "      <th>text</th>\n",
       "      <th>location</th>\n",
       "      <th>multi-team</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>repeatUser</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9434</th>\n",
       "      <td>TheJakeTyler</td>\n",
       "      <td>42497434.0</td>\n",
       "      <td>#TeamMystic let's get it!!!!</td>\n",
       "      <td>Virginia, USA</td>\n",
       "      <td>False</td>\n",
       "      <td>positive</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9435</th>\n",
       "      <td>LivAboveAverage</td>\n",
       "      <td>333182239.0</td>\n",
       "      <td>@AnthonyChott GO TEAM MYSTIC!!! #TeamMystic</td>\n",
       "      <td>Chesterfield, MO</td>\n",
       "      <td>False</td>\n",
       "      <td>positive</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9436</th>\n",
       "      <td>TylerDurden919</td>\n",
       "      <td>334394891.0</td>\n",
       "      <td>10:45 Saturday morning, everyone's at @Bojangl...</td>\n",
       "      <td>Durham, NC</td>\n",
       "      <td>False</td>\n",
       "      <td>positive</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           screenName       userId  \\\n",
       "9434     TheJakeTyler   42497434.0   \n",
       "9435  LivAboveAverage  333182239.0   \n",
       "9436   TylerDurden919  334394891.0   \n",
       "\n",
       "                                                   text          location  \\\n",
       "9434                       #TeamMystic let's get it!!!!     Virginia, USA   \n",
       "9435        @AnthonyChott GO TEAM MYSTIC!!! #TeamMystic  Chesterfield, MO   \n",
       "9436  10:45 Saturday morning, everyone's at @Bojangl...        Durham, NC   \n",
       "\n",
       "     multi-team sentiment repeatUser  \n",
       "9434      False  positive      False  \n",
       "9435      False  positive      False  \n",
       "9436      False  positive      False  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PoGo_tweets.tail(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'd like to extract the state information, regardless of which location format is being used.  To do so, we first define a dictionary of state abbreviations and the corresponding state name.  We also will want to create stand-alone lists of state abbreviations and state names from this dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dictionary of state abbreviations and names\n",
    "states = {\n",
    "        'AK': 'Alaska',\n",
    "        'AL': 'Alabama',\n",
    "        'AR': 'Arkansas',\n",
    "        'AZ': 'Arizona',\n",
    "        'CA': 'California',\n",
    "        'CO': 'Colorado',\n",
    "        'CT': 'Connecticut',\n",
    "        'DC': 'District of Columbia',\n",
    "        'DE': 'Delaware',\n",
    "        'FL': 'Florida',\n",
    "        'GA': 'Georgia',\n",
    "        'HI': 'Hawaii',\n",
    "        'IA': 'Iowa',\n",
    "        'ID': 'Idaho',\n",
    "        'IL': 'Illinois',\n",
    "        'IN': 'Indiana',\n",
    "        'KS': 'Kansas',\n",
    "        'KY': 'Kentucky',\n",
    "        'LA': 'Louisiana',\n",
    "        'MA': 'Massachusetts',\n",
    "        'MD': 'Maryland',\n",
    "        'ME': 'Maine',\n",
    "        'MI': 'Michigan',\n",
    "        'MN': 'Minnesota',\n",
    "        'MO': 'Missouri',\n",
    "        'MS': 'Mississippi',\n",
    "        'MT': 'Montana',\n",
    "        'NC': 'North Carolina',\n",
    "        'ND': 'North Dakota',\n",
    "        'NE': 'Nebraska',\n",
    "        'NH': 'New Hampshire',\n",
    "        'NJ': 'New Jersey',\n",
    "        'NM': 'New Mexico',\n",
    "        'NV': 'Nevada',\n",
    "        'NY': 'New York',\n",
    "        'OH': 'Ohio',\n",
    "        'OK': 'Oklahoma',\n",
    "        'OR': 'Oregon',\n",
    "        'PA': 'Pennsylvania',\n",
    "        'PR': 'Puerto Rico',\n",
    "        'RI': 'Rhode Island',\n",
    "        'SC': 'South Carolina',\n",
    "        'SD': 'South Dakota',\n",
    "        'TN': 'Tennessee',\n",
    "        'TX': 'Texas',\n",
    "        'UT': 'Utah',\n",
    "        'VA': 'Virginia',\n",
    "        'VT': 'Vermont',\n",
    "        'WA': 'Washington',\n",
    "        'WI': 'Wisconsin',\n",
    "        'WV': 'West Virginia',\n",
    "        'WY': 'Wyoming'\n",
    "}\n",
    "\n",
    "#Create a list of state abbreviations\n",
    "state_abbrevs=[state for state in states] \n",
    "\n",
    "#Create a list of state names\n",
    "state_names=[states[state] for state in states] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each tweet in our data frame, we can scan the location information to look for the state abbreviations or state names from our dictionary.  Some location information, such as \"New York, NY\" or \"Alabama, New York\" (yes, Alabama is a real city in New York) will contain multiple state names or abbreviations.  In this case, we'll want to identify the second name or abbreviation that appears in the location information.  The one exception to this rule is users from \"District of Columbia, Washington,\" where we'll want to use the first \"state\" name (District of Columbia) that appears.  Once we've extracted the state from the location information, we'll add it to a new column in our data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Function to determine the state that each tweet originated in\n",
    "def GetTweetState(dFrame):\n",
    "    \n",
    "    #Get a list of all the tweet's locations from our dataframe\n",
    "    loc_list=list(dFrame['location'])\n",
    "    \n",
    "    state_list=[]\n",
    "    \n",
    "    #Loop over the location info for each tweet\n",
    "    for info in loc_list:\n",
    "        \n",
    "        #See if a state abbreviation or name is in the location information\n",
    "        new_state = [state for state in state_names if state in info] + \\\n",
    "                    [states[state] for state in states if state in info]\n",
    "\n",
    "        #Handle cases like \"New York, NY\" and \"Alabama, New York\"\n",
    "        if (len(new_state) > 1) and new_state[0] != 'District of Columbia':\n",
    "            new_state = new_state[1].split('junk')\n",
    "            \n",
    "        #Handle \"District of Columbia, Washington\"     \n",
    "        elif len(new_state) > 1 and new_state[0] == 'District of Columbia':\n",
    "            new_state = new_state[0].split('junk')\n",
    "            \n",
    "        #Handle cases where no state is mentioned    \n",
    "        if not new_state:\n",
    "            new_state = ['None']\n",
    "\n",
    "        #After we determine the state, add it to a list\n",
    "        state_list+=new_state\n",
    "     \n",
    "    #Once we have the entire list of states, add it to the dataframe\n",
    "    dFrame['state']=state_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screenName</th>\n",
       "      <th>userId</th>\n",
       "      <th>text</th>\n",
       "      <th>location</th>\n",
       "      <th>multi-team</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>repeatUser</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9434</th>\n",
       "      <td>TheJakeTyler</td>\n",
       "      <td>42497434.0</td>\n",
       "      <td>#TeamMystic let's get it!!!!</td>\n",
       "      <td>Virginia, USA</td>\n",
       "      <td>False</td>\n",
       "      <td>positive</td>\n",
       "      <td>False</td>\n",
       "      <td>Virginia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9435</th>\n",
       "      <td>LivAboveAverage</td>\n",
       "      <td>333182239.0</td>\n",
       "      <td>@AnthonyChott GO TEAM MYSTIC!!! #TeamMystic</td>\n",
       "      <td>Chesterfield, MO</td>\n",
       "      <td>False</td>\n",
       "      <td>positive</td>\n",
       "      <td>False</td>\n",
       "      <td>Missouri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9436</th>\n",
       "      <td>TylerDurden919</td>\n",
       "      <td>334394891.0</td>\n",
       "      <td>10:45 Saturday morning, everyone's at @Bojangl...</td>\n",
       "      <td>Durham, NC</td>\n",
       "      <td>False</td>\n",
       "      <td>positive</td>\n",
       "      <td>False</td>\n",
       "      <td>North Carolina</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           screenName       userId  \\\n",
       "9434     TheJakeTyler   42497434.0   \n",
       "9435  LivAboveAverage  333182239.0   \n",
       "9436   TylerDurden919  334394891.0   \n",
       "\n",
       "                                                   text          location  \\\n",
       "9434                       #TeamMystic let's get it!!!!     Virginia, USA   \n",
       "9435        @AnthonyChott GO TEAM MYSTIC!!! #TeamMystic  Chesterfield, MO   \n",
       "9436  10:45 Saturday morning, everyone's at @Bojangl...        Durham, NC   \n",
       "\n",
       "     multi-team sentiment repeatUser           state  \n",
       "9434      False  positive      False        Virginia  \n",
       "9435      False  positive      False        Missouri  \n",
       "9436      False  positive      False  North Carolina  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GetTweetState(PoGo_tweets)\n",
    "GetTweetState(PoGo_tweets_nosenti)\n",
    "\n",
    "PoGo_tweets.tail(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"dominance\"></a> Measuring team dominance in each state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've identified the state each tweet is from, we can count how many tweets about each Pokemon Go team we collected in each state.  First, we initialize a new data frame with a row for each state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#stateInfo and stateInfo_ns\n",
    "def MakeStateInfo(dFrame):\n",
    "    dFrame['State']=states.values()\n",
    "    dFrame['Num Tweets'] = 0\n",
    "    dFrame['Num Red'] = 0\n",
    "    dFrame['Num Blue'] = 0\n",
    "    dFrame['Num Yellow'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Num Tweets</th>\n",
       "      <th>Num Red</th>\n",
       "      <th>Num Blue</th>\n",
       "      <th>Num Yellow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nebraska</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Michigan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Idaho</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          State  Num Tweets  Num Red  Num Blue  Num Yellow\n",
       "0  Pennsylvania           0        0         0           0\n",
       "1      Delaware           0        0         0           0\n",
       "2      Nebraska           0        0         0           0\n",
       "3      Michigan           0        0         0           0\n",
       "4         Idaho           0        0         0           0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stateInfo = pd.DataFrame()\n",
    "stateInfo_nosenti = pd.DataFrame()\n",
    "\n",
    "MakeStateInfo(stateInfo)\n",
    "MakeStateInfo(stateInfo_nosenti)\n",
    "\n",
    "stateInfo.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `stateInfo` dataframe is indexed with numbers by default.  Since each row represents a state, it would be more convenient to use the state names as the index.  We can tell Pandas to do this using the `set_index` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num Tweets</th>\n",
       "      <th>Num Red</th>\n",
       "      <th>Num Blue</th>\n",
       "      <th>Num Yellow</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pennsylvania</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Delaware</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nebraska</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Michigan</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Idaho</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Num Tweets  Num Red  Num Blue  Num Yellow\n",
       "State                                                  \n",
       "Pennsylvania           0        0         0           0\n",
       "Delaware               0        0         0           0\n",
       "Nebraska               0        0         0           0\n",
       "Michigan               0        0         0           0\n",
       "Idaho                  0        0         0           0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stateInfo = stateInfo.set_index(['State'])\n",
    "stateInfo_nosenti = stateInfo_nosenti.set_index(['State'])\n",
    "\n",
    "stateInfo.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we simply loop over each tweet in our collection.  For each tweet, we search for team-identifying phrases.  Once we've identified the team the tweet is referring to, we increase the count for that team in the corresponding state by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Lists of team identifying phrases\n",
    "yellow_text = ['#teaminstinct','#teamyellow','#instinct','team instinct']\n",
    "blue_text = ['#teammystic','#teamblue','#mystic','team mystic']\n",
    "red_text = ['#teamvalor','#teamred','#valor','team valor']\n",
    "\n",
    "#Function to populate the stateInfo data frame\n",
    "def PopStateInfo(state_dFrame,tweet_dFrame):\n",
    "    \n",
    "    #Loop over the tweet collection\n",
    "    for idx in range(len(tweet_dFrame)):\n",
    "        \n",
    "        #If we have state information for the tweet\n",
    "        if tweet_dFrame.ix[idx,'state'] != 'None':\n",
    "            \n",
    "            #Search for the team identifying phrases and\n",
    "            #Add one count to that team in state where the tweet came from \n",
    "            if any(hashtag in tweet_dFrame.ix[idx,'text'].lower() for hashtag in yellow_text):\n",
    "                state_dFrame.ix[tweet_dFrame.ix[idx,'state'],'Num Yellow'] += 1\n",
    "            elif any(hashtag in tweet_dFrame.ix[idx,'text'].lower() for hashtag in blue_text):\n",
    "                state_dFrame.ix[tweet_dFrame.ix[idx,'state'],'Num Blue'] += 1\n",
    "            elif any(hashtag in tweet_dFrame.ix[idx,'text'].lower() for hashtag in red_text):\n",
    "                state_dFrame.ix[tweet_dFrame.ix[idx,'state'],'Num Red'] += 1\n",
    "\n",
    "    #After we've process all tweets\n",
    "    #Count all the tweets in each state by adding red + blue + yellow\n",
    "    state_dFrame['Num Tweets'] = state_dFrame.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num Tweets</th>\n",
       "      <th>Num Red</th>\n",
       "      <th>Num Blue</th>\n",
       "      <th>Num Yellow</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pennsylvania</th>\n",
       "      <td>275</td>\n",
       "      <td>111</td>\n",
       "      <td>97</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Delaware</th>\n",
       "      <td>27</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nebraska</th>\n",
       "      <td>64</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Michigan</th>\n",
       "      <td>324</td>\n",
       "      <td>123</td>\n",
       "      <td>115</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Idaho</th>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Num Tweets  Num Red  Num Blue  Num Yellow\n",
       "State                                                  \n",
       "Pennsylvania         275      111        97          67\n",
       "Delaware              27       13         7           7\n",
       "Nebraska              64       26        23          15\n",
       "Michigan             324      123       115          86\n",
       "Idaho                 27       11         9           7"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PopStateInfo(stateInfo,PoGo_tweets)\n",
    "PopStateInfo(stateInfo_nosenti,PoGo_tweets_nosenti)\n",
    "\n",
    "stateInfo.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our metric for the dominance of each team in a state will simply be the fraction of tweets from that state that reference a particular team.  We can easily add this fraction to our data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to populate the stateInfo data frame\n",
    "def CalcDominance(dFrame):\n",
    "    dFrame['R Frac']=dFrame['Num Red']/dFrame['Num Tweets']\n",
    "    dFrame['Y Frac']=dFrame['Num Yellow']/dFrame['Num Tweets']\n",
    "    dFrame['B Frac']=dFrame['Num Blue']/dFrame['Num Tweets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num Tweets</th>\n",
       "      <th>Num Red</th>\n",
       "      <th>Num Blue</th>\n",
       "      <th>Num Yellow</th>\n",
       "      <th>R Frac</th>\n",
       "      <th>Y Frac</th>\n",
       "      <th>B Frac</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pennsylvania</th>\n",
       "      <td>275</td>\n",
       "      <td>111</td>\n",
       "      <td>97</td>\n",
       "      <td>67</td>\n",
       "      <td>0.403636</td>\n",
       "      <td>0.243636</td>\n",
       "      <td>0.352727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Delaware</th>\n",
       "      <td>27</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.259259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nebraska</th>\n",
       "      <td>64</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>0.359375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Michigan</th>\n",
       "      <td>324</td>\n",
       "      <td>123</td>\n",
       "      <td>115</td>\n",
       "      <td>86</td>\n",
       "      <td>0.379630</td>\n",
       "      <td>0.265432</td>\n",
       "      <td>0.354938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Idaho</th>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Num Tweets  Num Red  Num Blue  Num Yellow    R Frac    Y Frac  \\\n",
       "State                                                                         \n",
       "Pennsylvania         275      111        97          67  0.403636  0.243636   \n",
       "Delaware              27       13         7           7  0.481481  0.259259   \n",
       "Nebraska              64       26        23          15  0.406250  0.234375   \n",
       "Michigan             324      123       115          86  0.379630  0.265432   \n",
       "Idaho                 27       11         9           7  0.407407  0.259259   \n",
       "\n",
       "                B Frac  \n",
       "State                   \n",
       "Pennsylvania  0.352727  \n",
       "Delaware      0.259259  \n",
       "Nebraska      0.359375  \n",
       "Michigan      0.354938  \n",
       "Idaho         0.333333  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CalcDominance(stateInfo)\n",
    "CalcDominance(stateInfo_nosenti)\n",
    "\n",
    "stateInfo.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"stats\"></a> Statistical Analysis of the data\n",
    "\n",
    "In this section, I'll discuss how to properly account for statistical and systematic errors in each of our tweet counts, and how to propogate those errors to our team dominance metric.  Along the way, I'll also determine how many tweets are needed for our sentiment analyzer to improve the total error of our measurement.  I'll provide hyperlinks that will detail the mathematical concepts we'll be using, but without a strong understanding of statistics and calculus this section may be hard to follow.\n",
    "\n",
    "## Counting statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In statistics, a [Poisson distribution](https://www.pp.rhul.ac.uk/~cowan/stat/notes/PoissonNote.pdf) is used to describe the number of times an event occurs within a time interval.  This representation is appropriate if:\n",
    "\n",
    "* The number of times the event occurs ($\\mathsf{N}$) in an interval is discrete (0,1,2,...)\n",
    "* The event occurs independent of other events\n",
    "* The rate at which events occur is approximately constant.\n",
    "* The probability of events occuring at the same time is negligble.\n",
    "* The probability of an event occuring in an interval is proportional to the length of the interval.\n",
    "\n",
    "The number of Pokemon Go tweets within each state meets all of the above conditions, so we can use the Poisson distribution to determine the statistical error on our measurement.  The standard deviation of a Poisson distribution is given by the square root of the number of events observed.  (A derivation of this can be found in the previous link.)  Therefore, the statistical error of the count of tweets ($\\mathsf{N}$) is simply:\n",
    "\n",
    "$$\\mathsf{ \\sigma_{N,stat} = \\sqrt{N} }\\tag{1}$$\n",
    "\n",
    "From our last post, we know that 8.92% of our tweet collection is contaminated with negative tweets when we do not apply our sentiment analyzer.  Once we apply our sentiment analyzer to remove negative tweets, this contamination falls to 2.4%.  We can treat the contamination of negative tweets as a systematic uncertainity on the number of tweets we count in each state:\n",
    "\n",
    "$$\\mathsf{ \\sigma_{N, sys} = \\begin{cases}\n",
    "0.0892*N_{without \\; analyzer}  & \\text{if analyzer is not applied} \\\\\n",
    "0.0240*N_{with \\; analyzer} & \\text{if analyzer is applied}\n",
    "\\end{cases} }\\tag{2}\n",
    "$$\n",
    "\n",
    "Since the statistical and systematic errors on our tweet counts are uncorrelated, we can [add them in quadrature](http://physics.stackexchange.com/questions/23441/how-to-combine-measurement-error-with-statistic-error) to find the total error on our tweet counts:\n",
    "\n",
    "$$\\mathsf{ \\sigma_{N,tot} = \\sqrt{ \\sigma_{N,stat}^2 + \\sigma_{N,sys}^2} = \\begin{cases}\n",
    "\\sqrt{N_{without \\; analyzer} + (0.0892*N_{without \\; analyzer})^2}  & \\text{if analyzer is not applied} \\\\\n",
    "\\sqrt{N_{with \\; analyzer}+ (0.0240*N_{with \\; analyzer})^2} & \\text{if analyzer is applied}\n",
    "\\end{cases} }\\tag{3}$$\n",
    "\n",
    "## When is our sentiment analysis useful?\n",
    "\n",
    "Now that we know how to calculate the total error on our tweet counts, we can determine how many tweets we need for our sentiment analyzer to be useful.  Applying our sentiment analyzer will lower the total number of tweets in our collection.  In turn, this will lower both the absolute statistical and systematic error of our measurement.  It's important to realize that even though the absolute error on our tweet counts decreases as the total number of tweets decreases, the relative size of the error when compared to the number of tweets can still increase.  Instead, we must evaluate when our sentiment analyzer will lower the [relative error](http://mathworld.wolfram.com/RelativeError.html) of our measurement.  That is, we need to determine when:\n",
    "\n",
    "<a name=\"eq4\"></a>\n",
    "$$\\mathsf{ \\frac{ \\sqrt{ N_{without \\; analyzer} + 0.0892^2 * N_{without \\; analyzer}^2 } } {N_{without \\; analyzer}} \\ge \n",
    "\\frac{ \\sqrt{ N_{with \\; analyzer} + 0.0240^2 * N_{with \\; analyzer}^2 } }{N_{with \\; analyzer}} }\\tag{4}$$\n",
    "\n",
    "When we use our sentiment analyzer to reduce the number of negative tweets in our collection, any missclassified positive tweets will also be removed, and any misclassified negative tweets will remain.  Therefore, the number of remaining tweets after applying our sentiment analyzer is equal to:\n",
    "\n",
    "<a name=\"eq5\"></a>\n",
    "$$\\mathsf{ N_{with \\; analyzer} = 0.0892*N_{without \\;analyzer}*(1-R^-) + (1-0.0892)*N_{without \\; analyzer}*R^+ = 0.732 * N_{without \\;analyzer} }\\tag{5}$$\n",
    "\n",
    "Where I've used the fact that the negative recall of our classifier was $\\mathsf{R^- = 0.789}$, and the positive recall of our classifier was $\\mathsf{R^+=0.783}$. \n",
    "\n",
    "Plugging [Equation 5](#eq5) into [Equation 4](#eq4) and simplifying yields the result that our classifier will improve the relative error on our measurement when \n",
    "\n",
    "$$\\mathsf{ N_{without \\; analyzer} \\ge 50 }\\tag{6}$$\n",
    "\n",
    "\n",
    "## Propagating errors to our team dominance metric\n",
    "\n",
    "To make our team dominance map, we want to determine the fraction of tweets from each state that reference a particular team.  With the number of tweets about a team in a particular state given by $\\mathsf{N_{team}}$, and the number of total tweets in that state given by $\\mathsf{N_{state}}$, the dominance of a particlar team in a state is given by:\n",
    "\n",
    "$$\\mathsf{T \\equiv Team \\; Dominance =  \\frac{N_{team}}{N_{state}} } \\tag{6}$$\n",
    "\n",
    "To determine the error on the team dominance measurement, we need to propagate the invidual errors from the numerator and denominator.  The general equation for propagating the errors of numerous variables, $\\mathsf{\\mathbf{X} = \\lbrace x_1,x_2,x_3,\\dotsc,x_n \\rbrace}$, to some function of those variables $\\mathsf{F(\\mathbf{X})}$ is given by:\n",
    "\n",
    "<a name=\"eq7\"></a>\n",
    "$$\\mathsf{ \\sigma_F ^2 = \\sum_{i=1}^n \\sigma_{x_i}^2 \\left( \\frac{ \\delta F }{\\delta x_i} \\right)^2 + \\sum_{i=1}^n \\sum_{i \\ne j}^n \\sigma_{x_i,x_j}^2 \\left( \\frac{ \\delta F }{\\delta x_i} \\right)\\left( \\frac{ \\delta F }{\\delta x_j} \\right) }\\tag{7}$$\n",
    "\n",
    "where $\\mathsf{\\sigma_{x_i,x_j}^2}$ is the covariance of the variables $\\mathsf{x_i}$ and $\\mathsf{x_j}$.  In the case of uncorrelated variables, $\\mathsf{\\sigma_{x_i,x_j}^2 = 0}$, so the last term in [Equation 7](#eq7) vanishes.  \n",
    "\n",
    "As it stands, the variables in our team dominance measurement, $\\mathsf{N_{team}}$ and $\\mathsf{N_{state}}$, are correlated, since $\\mathsf{N_{state}}$ is equal to the sum of the tweet counts for each individual team.  To simplify our analysis, we can rewrite the team dominance equation in terms of the number of tweets referencing that team ($\\mathsf{N_{team}}$) and the number of tweets referencing a different team ($\\mathsf{N_{other}}$):\n",
    "\n",
    "<a name=\"eq8\"></a>\n",
    "$$\\mathsf{T =  \\frac{N_{team}}{N_{team} + N_{other}} } \\tag{8}$$\n",
    "\n",
    "[Equation 8](#eq8) has no correlated variables, so we don't need to worry about measuring the covariance of any terms when propogating error measurements.  Therefore, with the team dominance denoted as $\\mathsf{T}$,\n",
    "\n",
    "\n",
    "$$ \\mathsf{ \\sigma_T ^2 = \\sigma_{N_{team},tot}^2 \\left( \\frac{ \\delta T}{\\delta N_{team}} \\right)^2 + \\sigma_{N_{other},tot}^2 \\left( \\frac{ \\delta T }{\\delta N_{other}} \\right)^2 } \\tag{9}$$\n",
    "\n",
    "We can use the [product rule](https://www.math.ucdavis.edu/~kouba/CalcOneDIRECTORY/productruledirectory/ProductRule.html) to calculate the partial derivative of $\\mathsf{F}$ with respect to $\\mathsf{N_{team}}$:\n",
    "\n",
    "$$\\mathsf{ \\frac {\\delta T}{\\delta N_{team}} = \\frac{N_{other}}{(N_{team} + N_{other})^2} } \\tag{10}$$\n",
    "\n",
    "Similarly, we can use the [chain rule](https://en.wikipedia.org/wiki/Chain_rule) to calculate the partial derivative of $\\mathsf{F}$ with respect to $\\mathsf{N_{other}}$:\n",
    "\n",
    "$$\\mathsf{ \\frac {\\delta T}{\\delta N_{other}} = \\frac{-N_{team}}{(N_{team} + N_{other})^2} } \\tag{11}$$\n",
    "\n",
    "## Statistical Analysis Code\n",
    "\n",
    "Below, I've included the code that implements our statistical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def PopErrInfo(dFrame,sys_err):\n",
    "    \n",
    "    #Systematic errors from negative tweet contamination\n",
    "    y_sys_err = sys_err*dFrame['Num Yellow']\n",
    "    r_sys_err = sys_err*dFrame['Num Red']\n",
    "    b_sys_err = sys_err*dFrame['Num Blue']\n",
    "\n",
    "    #Statistical errors from Poisson counting\n",
    "    y_stat_err = dFrame['Num Yellow'] ** (1/2)\n",
    "    r_stat_err = dFrame['Num Red'] ** (1/2)\n",
    "    b_stat_err = dFrame['Num Blue'] ** (1/2)\n",
    "\n",
    "    #Total errors\n",
    "    y_tot_err = (y_stat_err ** 2 + y_sys_err **2) ** (1/2)\n",
    "    r_tot_err = (r_stat_err ** 2 + r_sys_err **2) ** (1/2)\n",
    "    b_tot_err = (b_stat_err ** 2 + b_sys_err **2) ** (1/2)\n",
    "\n",
    "\n",
    "    #Propagation of total errors to the team dominance metric\n",
    "    dFrame['R Frac Err']= ( (r_tot_err ** 2)*(dFrame['Num Blue'] + dFrame['Num Yellow'])**2 + \\\n",
    "                                dFrame['Num Red']**2 * (b_tot_err**2 + y_tot_err**2) ) ** (1/2) / \\\n",
    "                             (dFrame['Num Yellow'] + dFrame['Num Blue'] + dFrame['Num Red'])**2\n",
    "\n",
    "    dFrame['Y Frac Err']= ( (y_tot_err ** 2)*(dFrame['Num Blue'] + dFrame['Num Red'])**2 + \\\n",
    "                                dFrame['Num Yellow']**2 * (b_tot_err**2 + r_tot_err**2) ) ** (1/2) / \\\n",
    "                             (dFrame['Num Yellow'] + dFrame['Num Blue'] + dFrame['Num Red'])**2\n",
    "\n",
    "\n",
    "    dFrame['B Frac Err']= ( (b_tot_err ** 2)*(dFrame['Num Yellow'] + dFrame['Num Red'])**2 + \\\n",
    "                                dFrame['Num Blue']**2 * (y_tot_err**2 + r_tot_err**2) ) ** (1/2) / \\\n",
    "                             (dFrame['Num Yellow'] + dFrame['Num Blue'] + dFrame['Num Red'])**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sys_err_nosenti= 0.0892\n",
    "sys_err_senti  = 0.0240\n",
    "\n",
    "PopErrInfo(stateInfo,sys_err_senti)\n",
    "PopErrInfo(stateInfo_nosenti,sys_err_nosenti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num Tweets</th>\n",
       "      <th>Num Red</th>\n",
       "      <th>Num Blue</th>\n",
       "      <th>Num Yellow</th>\n",
       "      <th>R Frac</th>\n",
       "      <th>Y Frac</th>\n",
       "      <th>B Frac</th>\n",
       "      <th>R Frac Err</th>\n",
       "      <th>Y Frac Err</th>\n",
       "      <th>B Frac Err</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pennsylvania</th>\n",
       "      <td>275</td>\n",
       "      <td>111</td>\n",
       "      <td>97</td>\n",
       "      <td>67</td>\n",
       "      <td>0.403636</td>\n",
       "      <td>0.243636</td>\n",
       "      <td>0.352727</td>\n",
       "      <td>0.030429</td>\n",
       "      <td>0.026448</td>\n",
       "      <td>0.029600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Delaware</th>\n",
       "      <td>27</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.096439</td>\n",
       "      <td>0.084531</td>\n",
       "      <td>0.084531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nebraska</th>\n",
       "      <td>64</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>0.359375</td>\n",
       "      <td>0.061806</td>\n",
       "      <td>0.053213</td>\n",
       "      <td>0.060367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Michigan</th>\n",
       "      <td>324</td>\n",
       "      <td>123</td>\n",
       "      <td>115</td>\n",
       "      <td>86</td>\n",
       "      <td>0.379630</td>\n",
       "      <td>0.265432</td>\n",
       "      <td>0.354938</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.025192</td>\n",
       "      <td>0.027430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Idaho</th>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.094828</td>\n",
       "      <td>0.084526</td>\n",
       "      <td>0.090961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Num Tweets  Num Red  Num Blue  Num Yellow    R Frac    Y Frac  \\\n",
       "State                                                                         \n",
       "Pennsylvania         275      111        97          67  0.403636  0.243636   \n",
       "Delaware              27       13         7           7  0.481481  0.259259   \n",
       "Nebraska              64       26        23          15  0.406250  0.234375   \n",
       "Michigan             324      123       115          86  0.379630  0.265432   \n",
       "Idaho                 27       11         9           7  0.407407  0.259259   \n",
       "\n",
       "                B Frac  R Frac Err  Y Frac Err  B Frac Err  \n",
       "State                                                       \n",
       "Pennsylvania  0.352727    0.030429    0.026448    0.029600  \n",
       "Delaware      0.259259    0.096439    0.084531    0.084531  \n",
       "Nebraska      0.359375    0.061806    0.053213    0.060367  \n",
       "Michigan      0.354938    0.027841    0.025192    0.027430  \n",
       "Idaho         0.333333    0.094828    0.084526    0.090961  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stateInfo.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Note that in a given state the number of tweets from one team may exceed 50 counts, while the number of tweets from a different team may not.  In this case, the sentiment analyzer would improve the error on our measurement for one team, but not for the other.  To resolve this ambiguity, I calculated the average relative error for each of our team dominance metrics.  I then added a new column to our data frames that indicated if the sentiment analysis improved the average relative error for each state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#relative error = frac_err/frac\n",
    "def AverageRelErr(dFrame):\n",
    "    row_errs = []\n",
    "    for row in range(len(dFrame)): \n",
    "        rel_errs = []\n",
    "        if dFrame.ix[row,'Y Frac'] != 0:\n",
    "            rel_errs.append(dFrame.ix[row,'Y Frac Err']/dFrame.ix[row,'Y Frac'])\n",
    "\n",
    "        if dFrame.ix[row,'R Frac'] != 0:\n",
    "            rel_errs.append(dFrame.ix[row,'R Frac Err']/dFrame.ix[row,'R Frac'])\n",
    "\n",
    "        if dFrame.ix[row,'B Frac'] != 0:\n",
    "            rel_errs.append(dFrame.ix[row,'B Frac Err']/dFrame.ix[row,'B Frac'])\n",
    "\n",
    "        row_errs.append(np.average(rel_errs))\n",
    "    return row_errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stateInfo['Average Rel Err']=AverageRelErr(stateInfo)\n",
    "stateInfo_nosenti['Average Rel Err']=AverageRelErr(stateInfo_nosenti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num Tweets</th>\n",
       "      <th>Num Red</th>\n",
       "      <th>Num Blue</th>\n",
       "      <th>Num Yellow</th>\n",
       "      <th>R Frac</th>\n",
       "      <th>Y Frac</th>\n",
       "      <th>B Frac</th>\n",
       "      <th>R Frac Err</th>\n",
       "      <th>Y Frac Err</th>\n",
       "      <th>B Frac Err</th>\n",
       "      <th>Average Rel Err</th>\n",
       "      <th>Improved</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pennsylvania</th>\n",
       "      <td>275</td>\n",
       "      <td>111</td>\n",
       "      <td>97</td>\n",
       "      <td>67</td>\n",
       "      <td>0.403636</td>\n",
       "      <td>0.243636</td>\n",
       "      <td>0.352727</td>\n",
       "      <td>0.030429</td>\n",
       "      <td>0.026448</td>\n",
       "      <td>0.029600</td>\n",
       "      <td>0.089287</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Delaware</th>\n",
       "      <td>27</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.096439</td>\n",
       "      <td>0.084531</td>\n",
       "      <td>0.084531</td>\n",
       "      <td>0.284132</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nebraska</th>\n",
       "      <td>64</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>0.359375</td>\n",
       "      <td>0.061806</td>\n",
       "      <td>0.053213</td>\n",
       "      <td>0.060367</td>\n",
       "      <td>0.182386</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Michigan</th>\n",
       "      <td>324</td>\n",
       "      <td>123</td>\n",
       "      <td>115</td>\n",
       "      <td>86</td>\n",
       "      <td>0.379630</td>\n",
       "      <td>0.265432</td>\n",
       "      <td>0.354938</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.025192</td>\n",
       "      <td>0.027430</td>\n",
       "      <td>0.081843</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Idaho</th>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.094828</td>\n",
       "      <td>0.084526</td>\n",
       "      <td>0.090961</td>\n",
       "      <td>0.277224</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Num Tweets  Num Red  Num Blue  Num Yellow    R Frac    Y Frac  \\\n",
       "State                                                                         \n",
       "Pennsylvania         275      111        97          67  0.403636  0.243636   \n",
       "Delaware              27       13         7           7  0.481481  0.259259   \n",
       "Nebraska              64       26        23          15  0.406250  0.234375   \n",
       "Michigan             324      123       115          86  0.379630  0.265432   \n",
       "Idaho                 27       11         9           7  0.407407  0.259259   \n",
       "\n",
       "                B Frac  R Frac Err  Y Frac Err  B Frac Err  Average Rel Err  \\\n",
       "State                                                                         \n",
       "Pennsylvania  0.352727    0.030429    0.026448    0.029600         0.089287   \n",
       "Delaware      0.259259    0.096439    0.084531    0.084531         0.284132   \n",
       "Nebraska      0.359375    0.061806    0.053213    0.060367         0.182386   \n",
       "Michigan      0.354938    0.027841    0.025192    0.027430         0.081843   \n",
       "Idaho         0.333333    0.094828    0.084526    0.090961         0.277224   \n",
       "\n",
       "             Improved  \n",
       "State                  \n",
       "Pennsylvania     True  \n",
       "Delaware        False  \n",
       "Nebraska        False  \n",
       "Michigan         True  \n",
       "Idaho           False  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stateInfo['Improved'] = stateInfo['Average Rel Err'] <= stateInfo_nosenti['Average Rel Err']\n",
    "stateInfo.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end, the sentiment analysis improved the average relative error of our team dominance measurement in the following states:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pennsylvania\n",
      "Michigan\n",
      "Alabama\n",
      "Puerto Rico\n",
      "California\n",
      "Tennessee\n",
      "Illinois\n",
      "Nevada\n",
      "North Carolina\n",
      "South Dakota\n",
      "Washington\n",
      "Minnesota\n",
      "Kentucky\n",
      "Florida\n",
      "Ohio\n",
      "Indiana\n",
      "Massachusetts\n",
      "New Jersey\n",
      "Texas\n",
      "Oklahoma\n",
      "Georgia\n",
      "Arizona\n",
      "Virginia\n",
      "New York\n",
      "Maryland\n",
      "Oregon\n"
     ]
    }
   ],
   "source": [
    "for state in stateInfo.index[stateInfo['Improved'] == True]:\n",
    "    print (state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've finished our statistical analyis, let's save the data frames so that we can visualize the results in our next and final blog post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stateInfo.to_csv('stateInfo.csv')\n",
    "stateInfo_nosenti.to_csv('stateInfo_nosenti.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
