{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a sentiment analyzer using Python's Natrual Learning Toolkit.\n",
    "\n",
    "<!--more-->\n",
    "\n",
    "TABLE OF CONTENTS\n",
    "\n",
    "This is the fifth post in an on-going Pokemon Go analysis series.  Last time, we discussed how a Naive Bayes Classifier can be used to predict the class of a sample given a number of features about that sample.  In this post, we'll apply the technique to our Pokemon Go tweets to build a sentiment analyzer that automatically classifies whether each tweet has a positive or negative tone.  Once complete, we'll use the sentiment analyzer to remove negative tweets from our data set before using the positive tweets to map out the dominance of each team in each state.\n",
    "\n",
    "\n",
    "We'll cover the following topics:\n",
    "\n",
    "1. [Manually classifying a training set](#trainSet)\n",
    "2. [Python's Natural Learning Toolkit](#NLTK)\n",
    "3. [Extracting features from our data](#features)\n",
    "4. [Training our sentiment analyzer](#features)\n",
    "5. [Evaluating the analyzer's performance](#eval)\n",
    "\n",
    "\n",
    "# <a name=\"tweepy\"></a> Manually classying a training set\n",
    "\n",
    "Recall from our last post that the implementation of a Naive Bayes Classifier requires a training set of samples which have known features and known classes.  Right now, all of the tweets we've collected are unclassified.  Before we create our sentiment analyzer, we'll have to manually label a subset of the tweets as positive or negative to form our training set.  \n",
    "\n",
    "The process of manually labeling tweets is going to be time consuming and tedious, but we can use Python to make the process a little more bearable.  First, we'll import the Pandas and JSON libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you aren't familiar with the Pandas package, I highly recommend watching [Wes McKinney's tutorial](https://github.com/estimate/pandas-exercises) on the library that he created.  Pandas is designed to provide intuitive interactions with tabular data by introducing data frames to Python.  We'll be using it to create some data frames about our Pokemon Go tweets. Before we do so, we'll need to define a function that loads our Pokemon Go tweets from the JSON text file we created in the Tweepy blog post:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Define a function to load our Pokemon Go tweets\n",
    "def load_twitter_data(tweets_data_path):\n",
    "    tweets_data = []\n",
    "    \n",
    "    #Open the text file that contains the tweets we collected\n",
    "    tweets_file = open(tweets_data_path, \"r\")\n",
    "    \n",
    "    #Read the text file line by line\n",
    "    for line in tweets_file:\n",
    "        \n",
    "        #Append the content of each tweet to a tweets_data list\n",
    "        try:\n",
    "            tweet = json.loads(line)\n",
    "            tweets_data.append(tweet)\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "    #return the list of tweets_data\n",
    "    return tweets_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pop_tweets(path):\n",
    "    #Use the previous function to load our tweets from the text file\n",
    "    tweets_data = load_twitter_data(path)\n",
    "    \n",
    "    #Declare a new data frame with pandas, with some specific column names\n",
    "    tweets = pd.DataFrame(columns=['screenName','userId','text','latt','long','location'])\n",
    "\n",
    "    #For each tweet in the list\n",
    "    for tweet in tweets_data:\n",
    "        if ('text' in tweet): \n",
    "            if tweet['coordinates'] != None:\n",
    "                tweets.loc[len(tweets)]=[tweet['user']['screen_name'],tweet['user']['id'],tweet['text'], \\\n",
    "                                         tweet['coordinates']['coordinates'][0],\\\n",
    "                                         tweet['coordinates']['coordinates'][1],tweet['place']['full_name']]    \n",
    "            else:\n",
    "                tweets.loc[len(tweets)]=[tweet['user']['screen_name'],tweet['user']['id'],tweet['text'], \\\n",
    "                                         float('nan'),float('nan'),tweet['place']['full_name']]    \n",
    "        \n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PoGo_tweets = pop_tweets('PoGo_USA.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(PoGo_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Remove tweets that discuss two or more teams\n",
    "\n",
    "#Even though we didnt' track mystic, valor, and instinct alone when getting tweets\n",
    "#we can track them here since the tweets are specific to pokemon go \n",
    "for row in range(len(PoGo_tweets)):\n",
    "    has_b=any(word in PoGo_tweets.loc[row,'text'].lower() for word in ['team mystic','#teamblue','#teammystic','#mystic','mystic'])\n",
    "    has_r=any(word in PoGo_tweets.loc[row,'text'].lower() for word in ['team valor','#teamred','#teamvalor','#valor','valor'])\n",
    "    has_y=any(word in PoGo_tweets.loc[row,'text'].lower() for word in ['team instinct','#teamyellow','#teaminstinct','#instinct','instinct'])\n",
    "    if has_b+has_r+has_y > 1:\n",
    "        PoGo_tweets.loc[row,'multi-team']=True\n",
    "    else:\n",
    "        PoGo_tweets.loc[row,'multi-team']=False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Applying cut to remove multi-team tweets\n",
    "PoGo_tweets = PoGo_tweets[PoGo_tweets['multi-team'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(PoGo_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Select the first 2000 tweets to be manually labeled </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "isCont=input('Are you continuing from a previous checkpoint? (yes/no)')\n",
    "\n",
    "if isCont == 'yes':\n",
    "    #START HERE IF CONTINUING\n",
    "    #Import the csv dataframe\n",
    "    import pandas\n",
    "    from nltk.corpus import stopwords\n",
    "    PoGo_labeled = pandas.read_csv('PoGo_Sentiment_Labeled_extended.csv')\n",
    "    PoGo_labeled.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "else:\n",
    "    PoGo_labeled = PoGo_tweets.ix[:2000]\n",
    "    PoGo_labeled = PoGo_labeled.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PoGo_labeled.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(PoGo_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Extending PoGo_labeled to include more tweets\n",
    "PoGo_labeled = PoGo_labeled.append(PoGo_tweets.ix[4000:6000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(PoGo_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "backup = PoGo_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PoGo_labeled = PoGo_labeled.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Display the tweet for each row, and ask user to label it\n",
    "#Putting pos: Can identify user as being on team, neg: Negative tweet about a team, \n",
    "#or nan: Can identify as being on a diff team, or can't identify as being on team\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "#Left off at 3633\n",
    "for row in range(3960,4000):\n",
    "    print (PoGo_labeled.loc[row,'text'])\n",
    "    PoGo_labeled.loc[row,'sentiment'] = input()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Save the data </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PoGo_labeled.to_csv('PoGo_Sentiment_Labeled_extended.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
